{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividad 1: \n",
    "\n",
    "* Francelio Uriel Rodriguez Garcia - A01352663 \n",
    "* Juan Pablo Valenzuela Dorado - A00227321\n",
    "* Juan Pablo Bernal Lafarga - A01742342\n",
    "* Alfredo Murillo Madrigal - A01641791\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "1. Debido a que la composición de funciones lineales es también una función lineal:\n",
    "\n",
    "    Considerando una función lineal\n",
    "$$\n",
    "f(x)=a x+b\n",
    "$$\n",
    "donde $a$ y $b$ son constantes:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& f(f(x))=f(a x+b)=a(a x+b)+b =a^2 x+a b+b\n",
    "\\end{aligned}\n",
    "$$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\text { Si } c=a^2 \\text { y } d=a b+b \\\\\n",
    "& f(f(x))=c x+d\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Por lo tanto, si todas las funciones de activación de las neuronas son lineales, la salida va a ser una función lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ajusta un modelo perceptrón multicapa para este conjunto de datos (misterious_data_1) con dos clases y evalúa su rendimiento con validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.81      0.74      0.77       264\n",
      "         2.0       0.76      0.82      0.79       264\n",
      "\n",
      "    accuracy                           0.78       528\n",
      "   macro avg       0.78      0.78      0.78       528\n",
      "weighted avg       0.78      0.78      0.78       528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "\n",
    "# Load data\n",
    "data = np.loadtxt(\"C:/Users/franu/Downloads/RedesNeuronales/Actividad1/misterious_data_1.txt\") \n",
    "x = data[:,1:]\n",
    "y = data[:,0]\n",
    "\n",
    "# Train MLP classifier with all the available observations\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=10000)  # hidden_layer_sizes controls the number of neurons of each hidden layer.\n",
    "clf.fit(x, y)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "n_splits=5\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle = True)\n",
    "\n",
    "cv_y_test = []\n",
    "cv_y_pred = []\n",
    "\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "\n",
    "    # Training phase\n",
    "    x_train = x[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    clf_i = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=10000)\n",
    "    clf_i.fit(x_train, y_train)\n",
    "\n",
    "    # Test phase\n",
    "    x_test = x[test_index, :]\n",
    "    y_test = y[test_index]    \n",
    "    y_pred = clf_i.predict(x_test)\n",
    "\n",
    "    cv_y_test.append(y_test)\n",
    "    cv_y_pred.append(y_pred)\n",
    "\n",
    "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "85/85 [==============================] - 1s 5ms/step - loss: 0.8864 - accuracy: 0.4976 - val_loss: 0.7154 - val_accuracy: 0.4811\n",
      "Epoch 2/150\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.5474 - val_loss: 0.6561 - val_accuracy: 0.5472\n",
      "Epoch 3/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.6232 - val_loss: 0.6335 - val_accuracy: 0.6226\n",
      "Epoch 4/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7227 - val_loss: 0.6051 - val_accuracy: 0.6698\n",
      "Epoch 5/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7962 - val_loss: 0.5810 - val_accuracy: 0.7547\n",
      "Epoch 6/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8555 - val_loss: 0.5455 - val_accuracy: 0.7830\n",
      "Epoch 7/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8815 - val_loss: 0.5126 - val_accuracy: 0.7830\n",
      "Epoch 8/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.9076 - val_loss: 0.4653 - val_accuracy: 0.8113\n",
      "Epoch 9/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.9171 - val_loss: 0.4353 - val_accuracy: 0.8113\n",
      "Epoch 10/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9455 - val_loss: 0.4219 - val_accuracy: 0.8208\n",
      "Epoch 11/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9502 - val_loss: 0.4201 - val_accuracy: 0.8113\n",
      "Epoch 12/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1701 - accuracy: 0.9645 - val_loss: 0.4194 - val_accuracy: 0.8113\n",
      "Epoch 13/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9668 - val_loss: 0.4333 - val_accuracy: 0.8208\n",
      "Epoch 14/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9692 - val_loss: 0.4406 - val_accuracy: 0.8113\n",
      "Epoch 15/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.9787 - val_loss: 0.4495 - val_accuracy: 0.8208\n",
      "Epoch 16/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9763 - val_loss: 0.4624 - val_accuracy: 0.8302\n",
      "Epoch 17/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9810 - val_loss: 0.4717 - val_accuracy: 0.8208\n",
      "Epoch 18/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 0.9787 - val_loss: 0.5092 - val_accuracy: 0.8019\n",
      "Epoch 19/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9834 - val_loss: 0.5170 - val_accuracy: 0.8019\n",
      "Epoch 20/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9905 - val_loss: 0.5526 - val_accuracy: 0.8113\n",
      "Epoch 21/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9929 - val_loss: 0.5610 - val_accuracy: 0.7925\n",
      "Epoch 22/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9929 - val_loss: 0.5823 - val_accuracy: 0.8019\n",
      "Epoch 23/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9929 - val_loss: 0.5987 - val_accuracy: 0.8208\n",
      "Epoch 24/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9953 - val_loss: 0.6120 - val_accuracy: 0.8113\n",
      "Epoch 25/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9953 - val_loss: 0.6276 - val_accuracy: 0.8113\n",
      "Epoch 26/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9953 - val_loss: 0.6326 - val_accuracy: 0.8208\n",
      "Epoch 27/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9953 - val_loss: 0.6572 - val_accuracy: 0.8208\n",
      "Epoch 28/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9953 - val_loss: 0.6608 - val_accuracy: 0.8113\n",
      "Epoch 29/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9953 - val_loss: 0.6732 - val_accuracy: 0.8208\n",
      "Epoch 30/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9953 - val_loss: 0.6797 - val_accuracy: 0.8208\n",
      "Epoch 31/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9953 - val_loss: 0.6961 - val_accuracy: 0.8113\n",
      "Epoch 32/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 0.7058 - val_accuracy: 0.8113\n",
      "Epoch 33/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9953 - val_loss: 0.7198 - val_accuracy: 0.8113\n",
      "Epoch 34/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.7275 - val_accuracy: 0.8113\n",
      "Epoch 35/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 0.7319 - val_accuracy: 0.8208\n",
      "Epoch 36/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.7409 - val_accuracy: 0.8113\n",
      "Epoch 37/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.7454 - val_accuracy: 0.8019\n",
      "Epoch 38/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.7460 - val_accuracy: 0.8019\n",
      "Epoch 39/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.7490 - val_accuracy: 0.8019\n",
      "Epoch 40/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.7557 - val_accuracy: 0.8019\n",
      "Epoch 41/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.7700 - val_accuracy: 0.7925\n",
      "Epoch 42/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.7947 - val_accuracy: 0.8019\n",
      "Epoch 43/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.7894 - val_accuracy: 0.8019\n",
      "Epoch 44/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.7869 - val_accuracy: 0.8019\n",
      "Epoch 45/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.7840 - val_accuracy: 0.8019\n",
      "Epoch 46/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.7633 - val_accuracy: 0.8019\n",
      "Epoch 47/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.7621 - val_accuracy: 0.8019\n",
      "Epoch 48/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.7637 - val_accuracy: 0.7925\n",
      "Epoch 49/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.7610 - val_accuracy: 0.7925\n",
      "Epoch 50/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.7556 - val_accuracy: 0.8019\n",
      "Epoch 51/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.7637 - val_accuracy: 0.8019\n",
      "Epoch 52/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.8019\n",
      "Epoch 53/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.7576 - val_accuracy: 0.7925\n",
      "Epoch 54/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.7600 - val_accuracy: 0.8019\n",
      "Epoch 55/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.7656 - val_accuracy: 0.7925\n",
      "Epoch 56/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7684 - val_accuracy: 0.7925\n",
      "Epoch 57/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7697 - val_accuracy: 0.7925\n",
      "Epoch 58/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7861 - val_accuracy: 0.7925\n",
      "Epoch 59/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7885 - val_accuracy: 0.7830\n",
      "Epoch 60/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7996 - val_accuracy: 0.7830\n",
      "Epoch 61/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8069 - val_accuracy: 0.7925\n",
      "Epoch 62/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8102 - val_accuracy: 0.7830\n",
      "Epoch 63/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8199 - val_accuracy: 0.7830\n",
      "Epoch 64/150\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8217 - val_accuracy: 0.7830\n",
      "Epoch 65/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8330 - val_accuracy: 0.7830\n",
      "Epoch 66/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8355 - val_accuracy: 0.7830\n",
      "Epoch 67/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8432 - val_accuracy: 0.7830\n",
      "Epoch 68/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8526 - val_accuracy: 0.7830\n",
      "Epoch 69/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8521 - val_accuracy: 0.7736\n",
      "Epoch 70/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8576 - val_accuracy: 0.7830\n",
      "Epoch 71/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8611 - val_accuracy: 0.7925\n",
      "Epoch 72/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.7925\n",
      "Epoch 73/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8859 - val_accuracy: 0.7925\n",
      "Epoch 74/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8881 - val_accuracy: 0.8019\n",
      "Epoch 75/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9029 - val_accuracy: 0.8019\n",
      "Epoch 76/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9042 - val_accuracy: 0.8019\n",
      "Epoch 77/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9121 - val_accuracy: 0.8019\n",
      "Epoch 78/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9215 - val_accuracy: 0.7925\n",
      "Epoch 79/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9256 - val_accuracy: 0.8019\n",
      "Epoch 80/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9355 - val_accuracy: 0.8113\n",
      "Epoch 81/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9445 - val_accuracy: 0.8019\n",
      "Epoch 82/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9644 - val_accuracy: 0.7925\n",
      "Epoch 83/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.7925\n",
      "Epoch 84/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9669 - val_accuracy: 0.7925\n",
      "Epoch 85/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.9426e-04 - accuracy: 1.0000 - val_loss: 0.9736 - val_accuracy: 0.7925\n",
      "Epoch 86/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.6259e-04 - accuracy: 1.0000 - val_loss: 0.9826 - val_accuracy: 0.7925\n",
      "Epoch 87/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.1547e-04 - accuracy: 1.0000 - val_loss: 0.9860 - val_accuracy: 0.7925\n",
      "Epoch 88/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.7790e-04 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.8019\n",
      "Epoch 89/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.4289e-04 - accuracy: 1.0000 - val_loss: 1.0000 - val_accuracy: 0.8019\n",
      "Epoch 90/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.1587e-04 - accuracy: 1.0000 - val_loss: 1.0089 - val_accuracy: 0.8019\n",
      "Epoch 91/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.8344e-04 - accuracy: 1.0000 - val_loss: 1.0144 - val_accuracy: 0.8019\n",
      "Epoch 92/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.5073e-04 - accuracy: 1.0000 - val_loss: 1.0190 - val_accuracy: 0.8019\n",
      "Epoch 93/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.2525e-04 - accuracy: 1.0000 - val_loss: 1.0206 - val_accuracy: 0.7925\n",
      "Epoch 94/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.9105e-04 - accuracy: 1.0000 - val_loss: 1.0260 - val_accuracy: 0.8019\n",
      "Epoch 95/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.7147e-04 - accuracy: 1.0000 - val_loss: 1.0346 - val_accuracy: 0.8019\n",
      "Epoch 96/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.3777e-04 - accuracy: 1.0000 - val_loss: 1.0410 - val_accuracy: 0.8019\n",
      "Epoch 97/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.2080e-04 - accuracy: 1.0000 - val_loss: 1.0664 - val_accuracy: 0.8019\n",
      "Epoch 98/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.9046e-04 - accuracy: 1.0000 - val_loss: 1.0734 - val_accuracy: 0.8019\n",
      "Epoch 99/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.7336e-04 - accuracy: 1.0000 - val_loss: 1.0758 - val_accuracy: 0.8019\n",
      "Epoch 100/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.4154e-04 - accuracy: 1.0000 - val_loss: 1.0812 - val_accuracy: 0.8019\n",
      "Epoch 101/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.2714e-04 - accuracy: 1.0000 - val_loss: 1.0842 - val_accuracy: 0.8019\n",
      "Epoch 102/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.0202e-04 - accuracy: 1.0000 - val_loss: 1.0924 - val_accuracy: 0.8019\n",
      "Epoch 103/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.4062e-04 - accuracy: 1.0000 - val_loss: 1.0929 - val_accuracy: 0.8019\n",
      "Epoch 104/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.7269e-04 - accuracy: 1.0000 - val_loss: 1.0883 - val_accuracy: 0.8019\n",
      "Epoch 105/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.6937e-04 - accuracy: 1.0000 - val_loss: 1.0924 - val_accuracy: 0.8019\n",
      "Epoch 106/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.3008e-04 - accuracy: 1.0000 - val_loss: 1.0995 - val_accuracy: 0.8019\n",
      "Epoch 107/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.1113e-04 - accuracy: 1.0000 - val_loss: 1.1061 - val_accuracy: 0.8019\n",
      "Epoch 108/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.9112e-04 - accuracy: 1.0000 - val_loss: 1.1085 - val_accuracy: 0.8019\n",
      "Epoch 109/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.7804e-04 - accuracy: 1.0000 - val_loss: 1.1124 - val_accuracy: 0.8019\n",
      "Epoch 110/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.6276e-04 - accuracy: 1.0000 - val_loss: 1.1196 - val_accuracy: 0.8019\n",
      "Epoch 111/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.4929e-04 - accuracy: 1.0000 - val_loss: 1.1278 - val_accuracy: 0.8019\n",
      "Epoch 112/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.3088e-04 - accuracy: 1.0000 - val_loss: 1.1360 - val_accuracy: 0.8019\n",
      "Epoch 113/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.2195e-04 - accuracy: 1.0000 - val_loss: 1.1397 - val_accuracy: 0.8019\n",
      "Epoch 114/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.0763e-04 - accuracy: 1.0000 - val_loss: 1.1450 - val_accuracy: 0.8019\n",
      "Epoch 115/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.9408e-04 - accuracy: 1.0000 - val_loss: 1.1469 - val_accuracy: 0.8019\n",
      "Epoch 116/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.8284e-04 - accuracy: 1.0000 - val_loss: 1.1538 - val_accuracy: 0.8019\n",
      "Epoch 117/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.6894e-04 - accuracy: 1.0000 - val_loss: 1.1669 - val_accuracy: 0.8019\n",
      "Epoch 118/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.9151e-04 - accuracy: 1.0000 - val_loss: 1.1498 - val_accuracy: 0.8019\n",
      "Epoch 119/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.4758e-04 - accuracy: 1.0000 - val_loss: 1.1585 - val_accuracy: 0.8019\n",
      "Epoch 120/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.3925e-04 - accuracy: 1.0000 - val_loss: 1.1670 - val_accuracy: 0.8019\n",
      "Epoch 121/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.2930e-04 - accuracy: 1.0000 - val_loss: 1.1737 - val_accuracy: 0.8019\n",
      "Epoch 122/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.1963e-04 - accuracy: 1.0000 - val_loss: 1.1800 - val_accuracy: 0.8019\n",
      "Epoch 123/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.0945e-04 - accuracy: 1.0000 - val_loss: 1.1837 - val_accuracy: 0.8019\n",
      "Epoch 124/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.0175e-04 - accuracy: 1.0000 - val_loss: 1.1920 - val_accuracy: 0.8019\n",
      "Epoch 125/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.9154e-04 - accuracy: 1.0000 - val_loss: 1.1955 - val_accuracy: 0.8019\n",
      "Epoch 126/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8463e-04 - accuracy: 1.0000 - val_loss: 1.2047 - val_accuracy: 0.8019\n",
      "Epoch 127/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7799e-04 - accuracy: 1.0000 - val_loss: 1.2144 - val_accuracy: 0.8019\n",
      "Epoch 128/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7123e-04 - accuracy: 1.0000 - val_loss: 1.2192 - val_accuracy: 0.8019\n",
      "Epoch 129/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.6243e-04 - accuracy: 1.0000 - val_loss: 1.2248 - val_accuracy: 0.8019\n",
      "Epoch 130/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5616e-04 - accuracy: 1.0000 - val_loss: 1.2287 - val_accuracy: 0.8019\n",
      "Epoch 131/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5013e-04 - accuracy: 1.0000 - val_loss: 1.2490 - val_accuracy: 0.8019\n",
      "Epoch 132/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4376e-04 - accuracy: 1.0000 - val_loss: 1.2577 - val_accuracy: 0.8019\n",
      "Epoch 133/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3705e-04 - accuracy: 1.0000 - val_loss: 1.2594 - val_accuracy: 0.8019\n",
      "Epoch 134/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3027e-04 - accuracy: 1.0000 - val_loss: 1.2649 - val_accuracy: 0.8019\n",
      "Epoch 135/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2537e-04 - accuracy: 1.0000 - val_loss: 1.2728 - val_accuracy: 0.8019\n",
      "Epoch 136/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1938e-04 - accuracy: 1.0000 - val_loss: 1.2758 - val_accuracy: 0.8019\n",
      "Epoch 137/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1426e-04 - accuracy: 1.0000 - val_loss: 1.2804 - val_accuracy: 0.8019\n",
      "Epoch 138/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0942e-04 - accuracy: 1.0000 - val_loss: 1.2861 - val_accuracy: 0.8019\n",
      "Epoch 139/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0481e-04 - accuracy: 1.0000 - val_loss: 1.2917 - val_accuracy: 0.8019\n",
      "Epoch 140/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0093e-04 - accuracy: 1.0000 - val_loss: 1.2987 - val_accuracy: 0.8019\n",
      "Epoch 141/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.6358e-05 - accuracy: 1.0000 - val_loss: 1.3060 - val_accuracy: 0.8019\n",
      "Epoch 142/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.2203e-05 - accuracy: 1.0000 - val_loss: 1.3102 - val_accuracy: 0.8019\n",
      "Epoch 143/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.9130e-05 - accuracy: 1.0000 - val_loss: 1.3134 - val_accuracy: 0.8019\n",
      "Epoch 144/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.4692e-05 - accuracy: 1.0000 - val_loss: 1.3196 - val_accuracy: 0.8019\n",
      "Epoch 145/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.1319e-05 - accuracy: 1.0000 - val_loss: 1.3270 - val_accuracy: 0.8019\n",
      "Epoch 146/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.7935e-05 - accuracy: 1.0000 - val_loss: 1.3324 - val_accuracy: 0.8019\n",
      "Epoch 147/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.4418e-05 - accuracy: 1.0000 - val_loss: 1.3345 - val_accuracy: 0.8019\n",
      "Epoch 148/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.1416e-05 - accuracy: 1.0000 - val_loss: 1.3379 - val_accuracy: 0.8019\n",
      "Epoch 149/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.8260e-05 - accuracy: 1.0000 - val_loss: 1.3452 - val_accuracy: 0.8019\n",
      "Epoch 150/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.5481e-05 - accuracy: 1.0000 - val_loss: 1.3521 - val_accuracy: 0.8019\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Epoch 1/150\n",
      "85/85 [==============================] - 1s 3ms/step - loss: 0.6826 - accuracy: 0.5853 - val_loss: 0.6245 - val_accuracy: 0.6415\n",
      "Epoch 2/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7512 - val_loss: 0.5529 - val_accuracy: 0.6698\n",
      "Epoch 3/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8009 - val_loss: 0.4923 - val_accuracy: 0.7547\n",
      "Epoch 4/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8531 - val_loss: 0.4456 - val_accuracy: 0.8208\n",
      "Epoch 5/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8720 - val_loss: 0.4180 - val_accuracy: 0.8302\n",
      "Epoch 6/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.8981 - val_loss: 0.3997 - val_accuracy: 0.8396\n",
      "Epoch 7/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.9052 - val_loss: 0.3917 - val_accuracy: 0.8302\n",
      "Epoch 8/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9289 - val_loss: 0.3948 - val_accuracy: 0.8585\n",
      "Epoch 9/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9289 - val_loss: 0.4009 - val_accuracy: 0.8396\n",
      "Epoch 10/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9455 - val_loss: 0.4059 - val_accuracy: 0.8396\n",
      "Epoch 11/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9597 - val_loss: 0.4142 - val_accuracy: 0.8491\n",
      "Epoch 12/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.9645 - val_loss: 0.4302 - val_accuracy: 0.8585\n",
      "Epoch 13/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9692 - val_loss: 0.4244 - val_accuracy: 0.8585\n",
      "Epoch 14/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.9834 - val_loss: 0.4480 - val_accuracy: 0.8491\n",
      "Epoch 15/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9858 - val_loss: 0.4588 - val_accuracy: 0.8679\n",
      "Epoch 16/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9929 - val_loss: 0.4647 - val_accuracy: 0.8491\n",
      "Epoch 17/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9929 - val_loss: 0.4890 - val_accuracy: 0.8491\n",
      "Epoch 18/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9929 - val_loss: 0.4983 - val_accuracy: 0.8491\n",
      "Epoch 19/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9929 - val_loss: 0.5208 - val_accuracy: 0.8491\n",
      "Epoch 20/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9953 - val_loss: 0.5335 - val_accuracy: 0.8491\n",
      "Epoch 21/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9953 - val_loss: 0.5433 - val_accuracy: 0.8491\n",
      "Epoch 22/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9953 - val_loss: 0.5483 - val_accuracy: 0.8679\n",
      "Epoch 23/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9976 - val_loss: 0.5702 - val_accuracy: 0.8585\n",
      "Epoch 24/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.5906 - val_accuracy: 0.8491\n",
      "Epoch 25/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.6034 - val_accuracy: 0.8585\n",
      "Epoch 26/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.6169 - val_accuracy: 0.8585\n",
      "Epoch 27/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.6348 - val_accuracy: 0.8585\n",
      "Epoch 28/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.6511 - val_accuracy: 0.8585\n",
      "Epoch 29/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.6640 - val_accuracy: 0.8585\n",
      "Epoch 30/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.6757 - val_accuracy: 0.8585\n",
      "Epoch 31/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.6859 - val_accuracy: 0.8491\n",
      "Epoch 32/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.7002 - val_accuracy: 0.8491\n",
      "Epoch 33/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.8585\n",
      "Epoch 34/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.7269 - val_accuracy: 0.8491\n",
      "Epoch 35/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.7404 - val_accuracy: 0.8585\n",
      "Epoch 36/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.7535 - val_accuracy: 0.8491\n",
      "Epoch 37/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.7608 - val_accuracy: 0.8585\n",
      "Epoch 38/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7828 - val_accuracy: 0.8491\n",
      "Epoch 39/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7930 - val_accuracy: 0.8491\n",
      "Epoch 40/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.8396\n",
      "Epoch 41/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8134 - val_accuracy: 0.8491\n",
      "Epoch 42/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8226 - val_accuracy: 0.8396\n",
      "Epoch 43/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8337 - val_accuracy: 0.8491\n",
      "Epoch 44/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8404 - val_accuracy: 0.8396\n",
      "Epoch 45/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8530 - val_accuracy: 0.8491\n",
      "Epoch 46/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8627 - val_accuracy: 0.8491\n",
      "Epoch 47/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.8302\n",
      "Epoch 48/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8843 - val_accuracy: 0.8302\n",
      "Epoch 49/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8934 - val_accuracy: 0.8491\n",
      "Epoch 50/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9024 - val_accuracy: 0.8396\n",
      "Epoch 51/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9099 - val_accuracy: 0.8491\n",
      "Epoch 52/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9231 - val_accuracy: 0.8396\n",
      "Epoch 53/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9318 - val_accuracy: 0.8396\n",
      "Epoch 54/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9425 - val_accuracy: 0.8396\n",
      "Epoch 55/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9509 - val_accuracy: 0.8396\n",
      "Epoch 56/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9585 - val_accuracy: 0.8396\n",
      "Epoch 57/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.3887e-04 - accuracy: 1.0000 - val_loss: 0.9665 - val_accuracy: 0.8396\n",
      "Epoch 58/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.7946e-04 - accuracy: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.8396\n",
      "Epoch 59/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.2445e-04 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.8396\n",
      "Epoch 60/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.6671e-04 - accuracy: 1.0000 - val_loss: 0.9894 - val_accuracy: 0.8396\n",
      "Epoch 61/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.1205e-04 - accuracy: 1.0000 - val_loss: 1.0007 - val_accuracy: 0.8396\n",
      "Epoch 62/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.6512e-04 - accuracy: 1.0000 - val_loss: 1.0096 - val_accuracy: 0.8396\n",
      "Epoch 63/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.2720e-04 - accuracy: 1.0000 - val_loss: 1.0167 - val_accuracy: 0.8396\n",
      "Epoch 64/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.9012e-04 - accuracy: 1.0000 - val_loss: 1.0247 - val_accuracy: 0.8396\n",
      "Epoch 65/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.4965e-04 - accuracy: 1.0000 - val_loss: 1.0335 - val_accuracy: 0.8396\n",
      "Epoch 66/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.1783e-04 - accuracy: 1.0000 - val_loss: 1.0424 - val_accuracy: 0.8396\n",
      "Epoch 67/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.8644e-04 - accuracy: 1.0000 - val_loss: 1.0481 - val_accuracy: 0.8396\n",
      "Epoch 68/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.5574e-04 - accuracy: 1.0000 - val_loss: 1.0559 - val_accuracy: 0.8396\n",
      "Epoch 69/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.2870e-04 - accuracy: 1.0000 - val_loss: 1.0669 - val_accuracy: 0.8396\n",
      "Epoch 70/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.0187e-04 - accuracy: 1.0000 - val_loss: 1.0733 - val_accuracy: 0.8396\n",
      "Epoch 71/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.7956e-04 - accuracy: 1.0000 - val_loss: 1.0803 - val_accuracy: 0.8396\n",
      "Epoch 72/150\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 3.5625e-04 - accuracy: 1.0000 - val_loss: 1.0887 - val_accuracy: 0.8396\n",
      "Epoch 73/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.3599e-04 - accuracy: 1.0000 - val_loss: 1.0962 - val_accuracy: 0.8396\n",
      "Epoch 74/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.1917e-04 - accuracy: 1.0000 - val_loss: 1.1028 - val_accuracy: 0.8396\n",
      "Epoch 75/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.9801e-04 - accuracy: 1.0000 - val_loss: 1.1095 - val_accuracy: 0.8396\n",
      "Epoch 76/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.8394e-04 - accuracy: 1.0000 - val_loss: 1.1211 - val_accuracy: 0.8396\n",
      "Epoch 77/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.6538e-04 - accuracy: 1.0000 - val_loss: 1.1286 - val_accuracy: 0.8396\n",
      "Epoch 78/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.5093e-04 - accuracy: 1.0000 - val_loss: 1.1339 - val_accuracy: 0.8396\n",
      "Epoch 79/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.3637e-04 - accuracy: 1.0000 - val_loss: 1.1406 - val_accuracy: 0.8396\n",
      "Epoch 80/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.2306e-04 - accuracy: 1.0000 - val_loss: 1.1507 - val_accuracy: 0.8396\n",
      "Epoch 81/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.1035e-04 - accuracy: 1.0000 - val_loss: 1.1559 - val_accuracy: 0.8396\n",
      "Epoch 82/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.9953e-04 - accuracy: 1.0000 - val_loss: 1.1632 - val_accuracy: 0.8396\n",
      "Epoch 83/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8763e-04 - accuracy: 1.0000 - val_loss: 1.1701 - val_accuracy: 0.8396\n",
      "Epoch 84/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7714e-04 - accuracy: 1.0000 - val_loss: 1.1763 - val_accuracy: 0.8396\n",
      "Epoch 85/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.6610e-04 - accuracy: 1.0000 - val_loss: 1.1827 - val_accuracy: 0.8396\n",
      "Epoch 86/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5651e-04 - accuracy: 1.0000 - val_loss: 1.1888 - val_accuracy: 0.8396\n",
      "Epoch 87/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4749e-04 - accuracy: 1.0000 - val_loss: 1.1954 - val_accuracy: 0.8396\n",
      "Epoch 88/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3948e-04 - accuracy: 1.0000 - val_loss: 1.2022 - val_accuracy: 0.8396\n",
      "Epoch 89/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3170e-04 - accuracy: 1.0000 - val_loss: 1.2093 - val_accuracy: 0.8396\n",
      "Epoch 90/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2387e-04 - accuracy: 1.0000 - val_loss: 1.2171 - val_accuracy: 0.8396\n",
      "Epoch 91/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1752e-04 - accuracy: 1.0000 - val_loss: 1.2233 - val_accuracy: 0.8396\n",
      "Epoch 92/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1119e-04 - accuracy: 1.0000 - val_loss: 1.2288 - val_accuracy: 0.8396\n",
      "Epoch 93/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0550e-04 - accuracy: 1.0000 - val_loss: 1.2358 - val_accuracy: 0.8396\n",
      "Epoch 94/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.8695e-05 - accuracy: 1.0000 - val_loss: 1.2427 - val_accuracy: 0.8396\n",
      "Epoch 95/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.3333e-05 - accuracy: 1.0000 - val_loss: 1.2504 - val_accuracy: 0.8396\n",
      "Epoch 96/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.9664e-05 - accuracy: 1.0000 - val_loss: 1.2569 - val_accuracy: 0.8396\n",
      "Epoch 97/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.4250e-05 - accuracy: 1.0000 - val_loss: 1.2617 - val_accuracy: 0.8396\n",
      "Epoch 98/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.9630e-05 - accuracy: 1.0000 - val_loss: 1.2677 - val_accuracy: 0.8396\n",
      "Epoch 99/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.5198e-05 - accuracy: 1.0000 - val_loss: 1.2758 - val_accuracy: 0.8396\n",
      "Epoch 100/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.1611e-05 - accuracy: 1.0000 - val_loss: 1.2819 - val_accuracy: 0.8396\n",
      "Epoch 101/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.7412e-05 - accuracy: 1.0000 - val_loss: 1.2882 - val_accuracy: 0.8396\n",
      "Epoch 102/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.3910e-05 - accuracy: 1.0000 - val_loss: 1.2948 - val_accuracy: 0.8396\n",
      "Epoch 103/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.0737e-05 - accuracy: 1.0000 - val_loss: 1.3005 - val_accuracy: 0.8396\n",
      "Epoch 104/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.7424e-05 - accuracy: 1.0000 - val_loss: 1.3085 - val_accuracy: 0.8396\n",
      "Epoch 105/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.4465e-05 - accuracy: 1.0000 - val_loss: 1.3153 - val_accuracy: 0.8396\n",
      "Epoch 106/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.2033e-05 - accuracy: 1.0000 - val_loss: 1.3210 - val_accuracy: 0.8396\n",
      "Epoch 107/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.9163e-05 - accuracy: 1.0000 - val_loss: 1.3286 - val_accuracy: 0.8396\n",
      "Epoch 108/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.6506e-05 - accuracy: 1.0000 - val_loss: 1.3352 - val_accuracy: 0.8396\n",
      "Epoch 109/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.4357e-05 - accuracy: 1.0000 - val_loss: 1.3416 - val_accuracy: 0.8396\n",
      "Epoch 110/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.1908e-05 - accuracy: 1.0000 - val_loss: 1.3491 - val_accuracy: 0.8396\n",
      "Epoch 111/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.9902e-05 - accuracy: 1.0000 - val_loss: 1.3550 - val_accuracy: 0.8396\n",
      "Epoch 112/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.7949e-05 - accuracy: 1.0000 - val_loss: 1.3624 - val_accuracy: 0.8396\n",
      "Epoch 113/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.5863e-05 - accuracy: 1.0000 - val_loss: 1.3687 - val_accuracy: 0.8396\n",
      "Epoch 114/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.4068e-05 - accuracy: 1.0000 - val_loss: 1.3757 - val_accuracy: 0.8396\n",
      "Epoch 115/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.2409e-05 - accuracy: 1.0000 - val_loss: 1.3808 - val_accuracy: 0.8396\n",
      "Epoch 116/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.0709e-05 - accuracy: 1.0000 - val_loss: 1.3870 - val_accuracy: 0.8396\n",
      "Epoch 117/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.9173e-05 - accuracy: 1.0000 - val_loss: 1.3940 - val_accuracy: 0.8396\n",
      "Epoch 118/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.7685e-05 - accuracy: 1.0000 - val_loss: 1.3990 - val_accuracy: 0.8396\n",
      "Epoch 119/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.6603e-05 - accuracy: 1.0000 - val_loss: 1.4046 - val_accuracy: 0.8396\n",
      "Epoch 120/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.5080e-05 - accuracy: 1.0000 - val_loss: 1.4120 - val_accuracy: 0.8396\n",
      "Epoch 121/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.3792e-05 - accuracy: 1.0000 - val_loss: 1.4192 - val_accuracy: 0.8396\n",
      "Epoch 122/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.2716e-05 - accuracy: 1.0000 - val_loss: 1.4264 - val_accuracy: 0.8396\n",
      "Epoch 123/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.1623e-05 - accuracy: 1.0000 - val_loss: 1.4346 - val_accuracy: 0.8396\n",
      "Epoch 124/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.0510e-05 - accuracy: 1.0000 - val_loss: 1.4392 - val_accuracy: 0.8396\n",
      "Epoch 125/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.9509e-05 - accuracy: 1.0000 - val_loss: 1.4456 - val_accuracy: 0.8396\n",
      "Epoch 126/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8624e-05 - accuracy: 1.0000 - val_loss: 1.4522 - val_accuracy: 0.8396\n",
      "Epoch 127/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7568e-05 - accuracy: 1.0000 - val_loss: 1.4574 - val_accuracy: 0.8396\n",
      "Epoch 128/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.6758e-05 - accuracy: 1.0000 - val_loss: 1.4640 - val_accuracy: 0.8396\n",
      "Epoch 129/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5929e-05 - accuracy: 1.0000 - val_loss: 1.4706 - val_accuracy: 0.8396\n",
      "Epoch 130/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5169e-05 - accuracy: 1.0000 - val_loss: 1.4765 - val_accuracy: 0.8396\n",
      "Epoch 131/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4320e-05 - accuracy: 1.0000 - val_loss: 1.4849 - val_accuracy: 0.8396\n",
      "Epoch 132/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3564e-05 - accuracy: 1.0000 - val_loss: 1.4913 - val_accuracy: 0.8396\n",
      "Epoch 133/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2895e-05 - accuracy: 1.0000 - val_loss: 1.4969 - val_accuracy: 0.8396\n",
      "Epoch 134/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2302e-05 - accuracy: 1.0000 - val_loss: 1.5030 - val_accuracy: 0.8396\n",
      "Epoch 135/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1697e-05 - accuracy: 1.0000 - val_loss: 1.5097 - val_accuracy: 0.8396\n",
      "Epoch 136/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1077e-05 - accuracy: 1.0000 - val_loss: 1.5157 - val_accuracy: 0.8396\n",
      "Epoch 137/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0510e-05 - accuracy: 1.0000 - val_loss: 1.5232 - val_accuracy: 0.8396\n",
      "Epoch 138/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.9739e-06 - accuracy: 1.0000 - val_loss: 1.5273 - val_accuracy: 0.8396\n",
      "Epoch 139/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.5369e-06 - accuracy: 1.0000 - val_loss: 1.5346 - val_accuracy: 0.8396\n",
      "Epoch 140/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.0145e-06 - accuracy: 1.0000 - val_loss: 1.5402 - val_accuracy: 0.8396\n",
      "Epoch 141/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.5973e-06 - accuracy: 1.0000 - val_loss: 1.5449 - val_accuracy: 0.8396\n",
      "Epoch 142/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.1554e-06 - accuracy: 1.0000 - val_loss: 1.5521 - val_accuracy: 0.8396\n",
      "Epoch 143/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.7582e-06 - accuracy: 1.0000 - val_loss: 1.5593 - val_accuracy: 0.8396\n",
      "Epoch 144/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.3674e-06 - accuracy: 1.0000 - val_loss: 1.5667 - val_accuracy: 0.8396\n",
      "Epoch 145/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.9903e-06 - accuracy: 1.0000 - val_loss: 1.5720 - val_accuracy: 0.8396\n",
      "Epoch 146/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.6773e-06 - accuracy: 1.0000 - val_loss: 1.5786 - val_accuracy: 0.8396\n",
      "Epoch 147/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.3052e-06 - accuracy: 1.0000 - val_loss: 1.5836 - val_accuracy: 0.8396\n",
      "Epoch 148/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.0437e-06 - accuracy: 1.0000 - val_loss: 1.5899 - val_accuracy: 0.8396\n",
      "Epoch 149/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.6845e-06 - accuracy: 1.0000 - val_loss: 1.5964 - val_accuracy: 0.8396\n",
      "Epoch 150/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.4589e-06 - accuracy: 1.0000 - val_loss: 1.6031 - val_accuracy: 0.8396\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Epoch 1/150\n",
      "85/85 [==============================] - 1s 3ms/step - loss: 0.7054 - accuracy: 0.5284 - val_loss: 0.6672 - val_accuracy: 0.5849\n",
      "Epoch 2/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7299 - val_loss: 0.5879 - val_accuracy: 0.6698\n",
      "Epoch 3/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8128 - val_loss: 0.5436 - val_accuracy: 0.7170\n",
      "Epoch 4/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8602 - val_loss: 0.4975 - val_accuracy: 0.7264\n",
      "Epoch 5/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8839 - val_loss: 0.4790 - val_accuracy: 0.7453\n",
      "Epoch 6/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.8957 - val_loss: 0.4828 - val_accuracy: 0.7453\n",
      "Epoch 7/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9218 - val_loss: 0.5054 - val_accuracy: 0.7358\n",
      "Epoch 8/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9313 - val_loss: 0.5213 - val_accuracy: 0.7358\n",
      "Epoch 9/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.9336 - val_loss: 0.5711 - val_accuracy: 0.7264\n",
      "Epoch 10/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9384 - val_loss: 0.5921 - val_accuracy: 0.7264\n",
      "Epoch 11/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9455 - val_loss: 0.6087 - val_accuracy: 0.7358\n",
      "Epoch 12/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 0.9668 - val_loss: 0.6638 - val_accuracy: 0.7264\n",
      "Epoch 13/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9668 - val_loss: 0.6834 - val_accuracy: 0.7170\n",
      "Epoch 14/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9810 - val_loss: 0.7024 - val_accuracy: 0.7264\n",
      "Epoch 15/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9858 - val_loss: 0.7579 - val_accuracy: 0.7264\n",
      "Epoch 16/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9905 - val_loss: 0.7580 - val_accuracy: 0.7264\n",
      "Epoch 17/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9905 - val_loss: 0.7956 - val_accuracy: 0.7264\n",
      "Epoch 18/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9953 - val_loss: 0.8369 - val_accuracy: 0.7170\n",
      "Epoch 19/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9953 - val_loss: 0.8719 - val_accuracy: 0.7170\n",
      "Epoch 20/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9953 - val_loss: 0.8857 - val_accuracy: 0.7264\n",
      "Epoch 21/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9976 - val_loss: 0.9370 - val_accuracy: 0.7358\n",
      "Epoch 22/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9976 - val_loss: 0.9561 - val_accuracy: 0.7264\n",
      "Epoch 23/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9976 - val_loss: 0.9931 - val_accuracy: 0.7264\n",
      "Epoch 24/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9976 - val_loss: 1.0214 - val_accuracy: 0.7264\n",
      "Epoch 25/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.0461 - val_accuracy: 0.7264\n",
      "Epoch 26/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.0785 - val_accuracy: 0.7264\n",
      "Epoch 27/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.1053 - val_accuracy: 0.7264\n",
      "Epoch 28/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.1430 - val_accuracy: 0.7264\n",
      "Epoch 29/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.1615 - val_accuracy: 0.7264\n",
      "Epoch 30/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.1946 - val_accuracy: 0.7264\n",
      "Epoch 31/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.2198 - val_accuracy: 0.7264\n",
      "Epoch 32/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.2449 - val_accuracy: 0.7264\n",
      "Epoch 33/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2599 - val_accuracy: 0.7264\n",
      "Epoch 34/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2938 - val_accuracy: 0.7264\n",
      "Epoch 35/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3145 - val_accuracy: 0.7264\n",
      "Epoch 36/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3290 - val_accuracy: 0.7264\n",
      "Epoch 37/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.3626 - val_accuracy: 0.7264\n",
      "Epoch 38/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3791 - val_accuracy: 0.7264\n",
      "Epoch 39/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.4039 - val_accuracy: 0.7264\n",
      "Epoch 40/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4223 - val_accuracy: 0.7264\n",
      "Epoch 41/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4422 - val_accuracy: 0.7264\n",
      "Epoch 42/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4775 - val_accuracy: 0.7264\n",
      "Epoch 43/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.4982 - val_accuracy: 0.7264\n",
      "Epoch 44/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.5205 - val_accuracy: 0.7264\n",
      "Epoch 45/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5309 - val_accuracy: 0.7264\n",
      "Epoch 46/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.5529 - val_accuracy: 0.7264\n",
      "Epoch 47/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5725 - val_accuracy: 0.7264\n",
      "Epoch 48/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5866 - val_accuracy: 0.7264\n",
      "Epoch 49/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6092 - val_accuracy: 0.7264\n",
      "Epoch 50/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6244 - val_accuracy: 0.7264\n",
      "Epoch 51/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6430 - val_accuracy: 0.7264\n",
      "Epoch 52/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6534 - val_accuracy: 0.7264\n",
      "Epoch 53/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6651 - val_accuracy: 0.7264\n",
      "Epoch 54/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6787 - val_accuracy: 0.7264\n",
      "Epoch 55/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6930 - val_accuracy: 0.7264\n",
      "Epoch 56/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7116 - val_accuracy: 0.7264\n",
      "Epoch 57/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7278 - val_accuracy: 0.7264\n",
      "Epoch 58/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7422 - val_accuracy: 0.7264\n",
      "Epoch 59/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.5427e-04 - accuracy: 1.0000 - val_loss: 1.7578 - val_accuracy: 0.7264\n",
      "Epoch 60/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.0978e-04 - accuracy: 1.0000 - val_loss: 1.7709 - val_accuracy: 0.7264\n",
      "Epoch 61/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.6910e-04 - accuracy: 1.0000 - val_loss: 1.7861 - val_accuracy: 0.7264\n",
      "Epoch 62/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.2318e-04 - accuracy: 1.0000 - val_loss: 1.8020 - val_accuracy: 0.7264\n",
      "Epoch 63/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.8923e-04 - accuracy: 1.0000 - val_loss: 1.8201 - val_accuracy: 0.7264\n",
      "Epoch 64/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.5399e-04 - accuracy: 1.0000 - val_loss: 1.8325 - val_accuracy: 0.7264\n",
      "Epoch 65/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.2169e-04 - accuracy: 1.0000 - val_loss: 1.8451 - val_accuracy: 0.7264\n",
      "Epoch 66/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.9254e-04 - accuracy: 1.0000 - val_loss: 1.8611 - val_accuracy: 0.7264\n",
      "Epoch 67/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.6432e-04 - accuracy: 1.0000 - val_loss: 1.8709 - val_accuracy: 0.7264\n",
      "Epoch 68/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.3587e-04 - accuracy: 1.0000 - val_loss: 1.8847 - val_accuracy: 0.7264\n",
      "Epoch 69/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.1229e-04 - accuracy: 1.0000 - val_loss: 1.8962 - val_accuracy: 0.7264\n",
      "Epoch 70/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.8987e-04 - accuracy: 1.0000 - val_loss: 1.9121 - val_accuracy: 0.7264\n",
      "Epoch 71/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.6624e-04 - accuracy: 1.0000 - val_loss: 1.9276 - val_accuracy: 0.7264\n",
      "Epoch 72/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.4422e-04 - accuracy: 1.0000 - val_loss: 1.9383 - val_accuracy: 0.7264\n",
      "Epoch 73/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.2341e-04 - accuracy: 1.0000 - val_loss: 1.9549 - val_accuracy: 0.7264\n",
      "Epoch 74/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.0405e-04 - accuracy: 1.0000 - val_loss: 1.9737 - val_accuracy: 0.7264\n",
      "Epoch 75/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.4047e-04 - accuracy: 1.0000 - val_loss: 1.9628 - val_accuracy: 0.7358\n",
      "Epoch 76/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.7459e-04 - accuracy: 1.0000 - val_loss: 1.9774 - val_accuracy: 0.7358\n",
      "Epoch 77/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.5651e-04 - accuracy: 1.0000 - val_loss: 1.9927 - val_accuracy: 0.7358\n",
      "Epoch 78/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.3876e-04 - accuracy: 1.0000 - val_loss: 2.0049 - val_accuracy: 0.7358\n",
      "Epoch 79/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.2201e-04 - accuracy: 1.0000 - val_loss: 2.0207 - val_accuracy: 0.7358\n",
      "Epoch 80/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.0743e-04 - accuracy: 1.0000 - val_loss: 2.0349 - val_accuracy: 0.7358\n",
      "Epoch 81/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.9241e-04 - accuracy: 1.0000 - val_loss: 2.0440 - val_accuracy: 0.7358\n",
      "Epoch 82/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.7839e-04 - accuracy: 1.0000 - val_loss: 2.0585 - val_accuracy: 0.7358\n",
      "Epoch 83/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.6822e-04 - accuracy: 1.0000 - val_loss: 2.0700 - val_accuracy: 0.7358\n",
      "Epoch 84/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.5549e-04 - accuracy: 1.0000 - val_loss: 2.0812 - val_accuracy: 0.7358\n",
      "Epoch 85/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.4165e-04 - accuracy: 1.0000 - val_loss: 2.0965 - val_accuracy: 0.7358\n",
      "Epoch 86/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.2926e-04 - accuracy: 1.0000 - val_loss: 2.1102 - val_accuracy: 0.7358\n",
      "Epoch 87/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.1819e-04 - accuracy: 1.0000 - val_loss: 2.1238 - val_accuracy: 0.7358\n",
      "Epoch 88/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.1097e-04 - accuracy: 1.0000 - val_loss: 2.1218 - val_accuracy: 0.7358\n",
      "Epoch 89/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.9965e-04 - accuracy: 1.0000 - val_loss: 2.1379 - val_accuracy: 0.7358\n",
      "Epoch 90/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.8903e-04 - accuracy: 1.0000 - val_loss: 2.1521 - val_accuracy: 0.7358\n",
      "Epoch 91/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.7783e-04 - accuracy: 1.0000 - val_loss: 2.1614 - val_accuracy: 0.7358\n",
      "Epoch 92/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.6823e-04 - accuracy: 1.0000 - val_loss: 2.1764 - val_accuracy: 0.7358\n",
      "Epoch 93/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.6270e-04 - accuracy: 1.0000 - val_loss: 2.1837 - val_accuracy: 0.7453\n",
      "Epoch 94/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.5465e-04 - accuracy: 1.0000 - val_loss: 2.1820 - val_accuracy: 0.7453\n",
      "Epoch 95/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.4682e-04 - accuracy: 1.0000 - val_loss: 2.1920 - val_accuracy: 0.7547\n",
      "Epoch 96/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.3587e-04 - accuracy: 1.0000 - val_loss: 2.2122 - val_accuracy: 0.7453\n",
      "Epoch 97/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.2668e-04 - accuracy: 1.0000 - val_loss: 2.2232 - val_accuracy: 0.7358\n",
      "Epoch 98/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.1821e-04 - accuracy: 1.0000 - val_loss: 2.2342 - val_accuracy: 0.7453\n",
      "Epoch 99/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.1054e-04 - accuracy: 1.0000 - val_loss: 2.2427 - val_accuracy: 0.7358\n",
      "Epoch 100/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.0308e-04 - accuracy: 1.0000 - val_loss: 2.2563 - val_accuracy: 0.7358\n",
      "Epoch 101/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.9621e-04 - accuracy: 1.0000 - val_loss: 2.2670 - val_accuracy: 0.7358\n",
      "Epoch 102/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8918e-04 - accuracy: 1.0000 - val_loss: 2.2807 - val_accuracy: 0.7358\n",
      "Epoch 103/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8256e-04 - accuracy: 1.0000 - val_loss: 2.2923 - val_accuracy: 0.7358\n",
      "Epoch 104/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7665e-04 - accuracy: 1.0000 - val_loss: 2.2997 - val_accuracy: 0.7358\n",
      "Epoch 105/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7063e-04 - accuracy: 1.0000 - val_loss: 2.3165 - val_accuracy: 0.7453\n",
      "Epoch 106/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.6429e-04 - accuracy: 1.0000 - val_loss: 2.3252 - val_accuracy: 0.7453\n",
      "Epoch 107/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5863e-04 - accuracy: 1.0000 - val_loss: 2.3400 - val_accuracy: 0.7453\n",
      "Epoch 108/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5317e-04 - accuracy: 1.0000 - val_loss: 2.3510 - val_accuracy: 0.7453\n",
      "Epoch 109/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4784e-04 - accuracy: 1.0000 - val_loss: 2.3640 - val_accuracy: 0.7453\n",
      "Epoch 110/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4273e-04 - accuracy: 1.0000 - val_loss: 2.3725 - val_accuracy: 0.7453\n",
      "Epoch 111/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3773e-04 - accuracy: 1.0000 - val_loss: 2.3875 - val_accuracy: 0.7453\n",
      "Epoch 112/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3312e-04 - accuracy: 1.0000 - val_loss: 2.3969 - val_accuracy: 0.7453\n",
      "Epoch 113/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2846e-04 - accuracy: 1.0000 - val_loss: 2.4054 - val_accuracy: 0.7453\n",
      "Epoch 114/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2401e-04 - accuracy: 1.0000 - val_loss: 2.4216 - val_accuracy: 0.7453\n",
      "Epoch 115/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1972e-04 - accuracy: 1.0000 - val_loss: 2.4310 - val_accuracy: 0.7453\n",
      "Epoch 116/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1550e-04 - accuracy: 1.0000 - val_loss: 2.4428 - val_accuracy: 0.7453\n",
      "Epoch 117/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1147e-04 - accuracy: 1.0000 - val_loss: 2.4547 - val_accuracy: 0.7453\n",
      "Epoch 118/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0753e-04 - accuracy: 1.0000 - val_loss: 2.4647 - val_accuracy: 0.7453\n",
      "Epoch 119/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0380e-04 - accuracy: 1.0000 - val_loss: 2.4755 - val_accuracy: 0.7453\n",
      "Epoch 120/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0085e-04 - accuracy: 1.0000 - val_loss: 2.4875 - val_accuracy: 0.7453\n",
      "Epoch 121/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.6621e-05 - accuracy: 1.0000 - val_loss: 2.5014 - val_accuracy: 0.7453\n",
      "Epoch 122/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.3324e-05 - accuracy: 1.0000 - val_loss: 2.5132 - val_accuracy: 0.7453\n",
      "Epoch 123/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.0008e-05 - accuracy: 1.0000 - val_loss: 2.5256 - val_accuracy: 0.7453\n",
      "Epoch 124/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.6808e-05 - accuracy: 1.0000 - val_loss: 2.5321 - val_accuracy: 0.7453\n",
      "Epoch 125/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.3779e-05 - accuracy: 1.0000 - val_loss: 2.5467 - val_accuracy: 0.7453\n",
      "Epoch 126/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.0791e-05 - accuracy: 1.0000 - val_loss: 2.5578 - val_accuracy: 0.7453\n",
      "Epoch 127/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.7933e-05 - accuracy: 1.0000 - val_loss: 2.5695 - val_accuracy: 0.7453\n",
      "Epoch 128/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.5136e-05 - accuracy: 1.0000 - val_loss: 2.5814 - val_accuracy: 0.7453\n",
      "Epoch 129/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.2463e-05 - accuracy: 1.0000 - val_loss: 2.5937 - val_accuracy: 0.7453\n",
      "Epoch 130/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.9883e-05 - accuracy: 1.0000 - val_loss: 2.6007 - val_accuracy: 0.7453\n",
      "Epoch 131/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.7352e-05 - accuracy: 1.0000 - val_loss: 2.6153 - val_accuracy: 0.7453\n",
      "Epoch 132/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.4954e-05 - accuracy: 1.0000 - val_loss: 2.6247 - val_accuracy: 0.7453\n",
      "Epoch 133/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.2608e-05 - accuracy: 1.0000 - val_loss: 2.6363 - val_accuracy: 0.7453\n",
      "Epoch 134/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.0303e-05 - accuracy: 1.0000 - val_loss: 2.6490 - val_accuracy: 0.7453\n",
      "Epoch 135/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.8123e-05 - accuracy: 1.0000 - val_loss: 2.6570 - val_accuracy: 0.7453\n",
      "Epoch 136/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.6002e-05 - accuracy: 1.0000 - val_loss: 2.6737 - val_accuracy: 0.7453\n",
      "Epoch 137/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.3960e-05 - accuracy: 1.0000 - val_loss: 2.6807 - val_accuracy: 0.7453\n",
      "Epoch 138/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.1994e-05 - accuracy: 1.0000 - val_loss: 2.6909 - val_accuracy: 0.7453\n",
      "Epoch 139/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.0110e-05 - accuracy: 1.0000 - val_loss: 2.7032 - val_accuracy: 0.7453\n",
      "Epoch 140/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.8279e-05 - accuracy: 1.0000 - val_loss: 2.7136 - val_accuracy: 0.7547\n",
      "Epoch 141/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.6506e-05 - accuracy: 1.0000 - val_loss: 2.7245 - val_accuracy: 0.7547\n",
      "Epoch 142/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.4808e-05 - accuracy: 1.0000 - val_loss: 2.7353 - val_accuracy: 0.7547\n",
      "Epoch 143/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.3165e-05 - accuracy: 1.0000 - val_loss: 2.7478 - val_accuracy: 0.7547\n",
      "Epoch 144/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.1643e-05 - accuracy: 1.0000 - val_loss: 2.7570 - val_accuracy: 0.7547\n",
      "Epoch 145/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.0078e-05 - accuracy: 1.0000 - val_loss: 2.7679 - val_accuracy: 0.7547\n",
      "Epoch 146/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.8616e-05 - accuracy: 1.0000 - val_loss: 2.7808 - val_accuracy: 0.7547\n",
      "Epoch 147/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.7212e-05 - accuracy: 1.0000 - val_loss: 2.7894 - val_accuracy: 0.7547\n",
      "Epoch 148/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.5844e-05 - accuracy: 1.0000 - val_loss: 2.7997 - val_accuracy: 0.7547\n",
      "Epoch 149/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.4517e-05 - accuracy: 1.0000 - val_loss: 2.8115 - val_accuracy: 0.7547\n",
      "Epoch 150/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.3215e-05 - accuracy: 1.0000 - val_loss: 2.8228 - val_accuracy: 0.7547\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Epoch 1/150\n",
      "85/85 [==============================] - 1s 3ms/step - loss: 0.6714 - accuracy: 0.5887 - val_loss: 0.6271 - val_accuracy: 0.6667\n",
      "Epoch 2/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7423 - val_loss: 0.5617 - val_accuracy: 0.7143\n",
      "Epoch 3/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8274 - val_loss: 0.5140 - val_accuracy: 0.7714\n",
      "Epoch 4/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.8582 - val_loss: 0.5123 - val_accuracy: 0.7810\n",
      "Epoch 5/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.8960 - val_loss: 0.5320 - val_accuracy: 0.7524\n",
      "Epoch 6/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9267 - val_loss: 0.5711 - val_accuracy: 0.7619\n",
      "Epoch 7/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.9433 - val_loss: 0.6253 - val_accuracy: 0.7238\n",
      "Epoch 8/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.9456 - val_loss: 0.6524 - val_accuracy: 0.7429\n",
      "Epoch 9/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9645 - val_loss: 0.7089 - val_accuracy: 0.7333\n",
      "Epoch 10/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 0.9716 - val_loss: 0.7657 - val_accuracy: 0.7333\n",
      "Epoch 11/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.9764 - val_loss: 0.8363 - val_accuracy: 0.7238\n",
      "Epoch 12/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9882 - val_loss: 0.9185 - val_accuracy: 0.7048\n",
      "Epoch 13/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9882 - val_loss: 0.9579 - val_accuracy: 0.7238\n",
      "Epoch 14/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9929 - val_loss: 1.0156 - val_accuracy: 0.7143\n",
      "Epoch 15/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.9953 - val_loss: 1.0826 - val_accuracy: 0.7238\n",
      "Epoch 16/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9953 - val_loss: 1.1478 - val_accuracy: 0.7143\n",
      "Epoch 17/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9976 - val_loss: 1.2086 - val_accuracy: 0.7048\n",
      "Epoch 18/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9976 - val_loss: 1.2657 - val_accuracy: 0.7048\n",
      "Epoch 19/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9976 - val_loss: 1.3056 - val_accuracy: 0.7143\n",
      "Epoch 20/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 1.3617 - val_accuracy: 0.7048\n",
      "Epoch 21/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.3935 - val_accuracy: 0.7048\n",
      "Epoch 22/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.4225 - val_accuracy: 0.7048\n",
      "Epoch 23/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.4773 - val_accuracy: 0.7048\n",
      "Epoch 24/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5091 - val_accuracy: 0.7048\n",
      "Epoch 25/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.5478 - val_accuracy: 0.7048\n",
      "Epoch 26/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.5872 - val_accuracy: 0.7048\n",
      "Epoch 27/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.6158 - val_accuracy: 0.7048\n",
      "Epoch 28/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.6544 - val_accuracy: 0.7048\n",
      "Epoch 29/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.6828 - val_accuracy: 0.7048\n",
      "Epoch 30/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.7087 - val_accuracy: 0.7048\n",
      "Epoch 31/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.7349 - val_accuracy: 0.7048\n",
      "Epoch 32/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.7692 - val_accuracy: 0.7048\n",
      "Epoch 33/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.7943 - val_accuracy: 0.7048\n",
      "Epoch 34/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8216 - val_accuracy: 0.7048\n",
      "Epoch 35/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.8459 - val_accuracy: 0.7048\n",
      "Epoch 36/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8671 - val_accuracy: 0.7048\n",
      "Epoch 37/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.8925 - val_accuracy: 0.7048\n",
      "Epoch 38/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9230 - val_accuracy: 0.7048\n",
      "Epoch 39/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9407 - val_accuracy: 0.7048\n",
      "Epoch 40/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9585 - val_accuracy: 0.7048\n",
      "Epoch 41/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9820 - val_accuracy: 0.7143\n",
      "Epoch 42/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.0051 - val_accuracy: 0.7143\n",
      "Epoch 43/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.8396e-04 - accuracy: 1.0000 - val_loss: 2.0249 - val_accuracy: 0.7143\n",
      "Epoch 44/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.0940e-04 - accuracy: 1.0000 - val_loss: 2.0472 - val_accuracy: 0.7238\n",
      "Epoch 45/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.3637e-04 - accuracy: 1.0000 - val_loss: 2.0651 - val_accuracy: 0.7238\n",
      "Epoch 46/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.8654e-04 - accuracy: 1.0000 - val_loss: 2.0859 - val_accuracy: 0.7238\n",
      "Epoch 47/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.2740e-04 - accuracy: 1.0000 - val_loss: 2.1094 - val_accuracy: 0.7238\n",
      "Epoch 48/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.6852e-04 - accuracy: 1.0000 - val_loss: 2.1252 - val_accuracy: 0.7238\n",
      "Epoch 49/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.2229e-04 - accuracy: 1.0000 - val_loss: 2.1445 - val_accuracy: 0.7238\n",
      "Epoch 50/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.8080e-04 - accuracy: 1.0000 - val_loss: 2.1630 - val_accuracy: 0.7238\n",
      "Epoch 51/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.4298e-04 - accuracy: 1.0000 - val_loss: 2.1820 - val_accuracy: 0.7238\n",
      "Epoch 52/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.0499e-04 - accuracy: 1.0000 - val_loss: 2.1966 - val_accuracy: 0.7238\n",
      "Epoch 53/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.7002e-04 - accuracy: 1.0000 - val_loss: 2.2155 - val_accuracy: 0.7238\n",
      "Epoch 54/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.4026e-04 - accuracy: 1.0000 - val_loss: 2.2361 - val_accuracy: 0.7238\n",
      "Epoch 55/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.1112e-04 - accuracy: 1.0000 - val_loss: 2.2517 - val_accuracy: 0.7238\n",
      "Epoch 56/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.8496e-04 - accuracy: 1.0000 - val_loss: 2.2689 - val_accuracy: 0.7333\n",
      "Epoch 57/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.6332e-04 - accuracy: 1.0000 - val_loss: 2.2876 - val_accuracy: 0.7238\n",
      "Epoch 58/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.3925e-04 - accuracy: 1.0000 - val_loss: 2.3014 - val_accuracy: 0.7238\n",
      "Epoch 59/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.1748e-04 - accuracy: 1.0000 - val_loss: 2.3183 - val_accuracy: 0.7238\n",
      "Epoch 60/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.9759e-04 - accuracy: 1.0000 - val_loss: 2.3364 - val_accuracy: 0.7333\n",
      "Epoch 61/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.8028e-04 - accuracy: 1.0000 - val_loss: 2.3532 - val_accuracy: 0.7333\n",
      "Epoch 62/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.6300e-04 - accuracy: 1.0000 - val_loss: 2.3683 - val_accuracy: 0.7333\n",
      "Epoch 63/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.4838e-04 - accuracy: 1.0000 - val_loss: 2.3863 - val_accuracy: 0.7238\n",
      "Epoch 64/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.3329e-04 - accuracy: 1.0000 - val_loss: 2.4013 - val_accuracy: 0.7333\n",
      "Epoch 65/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.2141e-04 - accuracy: 1.0000 - val_loss: 2.4165 - val_accuracy: 0.7333\n",
      "Epoch 66/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.0786e-04 - accuracy: 1.0000 - val_loss: 2.4357 - val_accuracy: 0.7333\n",
      "Epoch 67/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.9524e-04 - accuracy: 1.0000 - val_loss: 2.4468 - val_accuracy: 0.7333\n",
      "Epoch 68/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8362e-04 - accuracy: 1.0000 - val_loss: 2.4639 - val_accuracy: 0.7333\n",
      "Epoch 69/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7338e-04 - accuracy: 1.0000 - val_loss: 2.4785 - val_accuracy: 0.7333\n",
      "Epoch 70/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.6370e-04 - accuracy: 1.0000 - val_loss: 2.4967 - val_accuracy: 0.7333\n",
      "Epoch 71/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5404e-04 - accuracy: 1.0000 - val_loss: 2.5115 - val_accuracy: 0.7333\n",
      "Epoch 72/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4592e-04 - accuracy: 1.0000 - val_loss: 2.5317 - val_accuracy: 0.7333\n",
      "Epoch 73/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3742e-04 - accuracy: 1.0000 - val_loss: 2.5456 - val_accuracy: 0.7333\n",
      "Epoch 74/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2942e-04 - accuracy: 1.0000 - val_loss: 2.5585 - val_accuracy: 0.7333\n",
      "Epoch 75/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2229e-04 - accuracy: 1.0000 - val_loss: 2.5695 - val_accuracy: 0.7333\n",
      "Epoch 76/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1557e-04 - accuracy: 1.0000 - val_loss: 2.5873 - val_accuracy: 0.7333\n",
      "Epoch 77/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0933e-04 - accuracy: 1.0000 - val_loss: 2.6031 - val_accuracy: 0.7333\n",
      "Epoch 78/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0330e-04 - accuracy: 1.0000 - val_loss: 2.6191 - val_accuracy: 0.7333\n",
      "Epoch 79/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.7783e-05 - accuracy: 1.0000 - val_loss: 2.6313 - val_accuracy: 0.7333\n",
      "Epoch 80/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.2587e-05 - accuracy: 1.0000 - val_loss: 2.6479 - val_accuracy: 0.7333\n",
      "Epoch 81/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.7454e-05 - accuracy: 1.0000 - val_loss: 2.6616 - val_accuracy: 0.7333\n",
      "Epoch 82/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.2679e-05 - accuracy: 1.0000 - val_loss: 2.6745 - val_accuracy: 0.7333\n",
      "Epoch 83/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.8158e-05 - accuracy: 1.0000 - val_loss: 2.6892 - val_accuracy: 0.7333\n",
      "Epoch 84/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.4075e-05 - accuracy: 1.0000 - val_loss: 2.7053 - val_accuracy: 0.7333\n",
      "Epoch 85/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.0005e-05 - accuracy: 1.0000 - val_loss: 2.7222 - val_accuracy: 0.7333\n",
      "Epoch 86/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.6501e-05 - accuracy: 1.0000 - val_loss: 2.7315 - val_accuracy: 0.7429\n",
      "Epoch 87/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.3004e-05 - accuracy: 1.0000 - val_loss: 2.7446 - val_accuracy: 0.7429\n",
      "Epoch 88/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.9412e-05 - accuracy: 1.0000 - val_loss: 2.7618 - val_accuracy: 0.7429\n",
      "Epoch 89/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.6418e-05 - accuracy: 1.0000 - val_loss: 2.7791 - val_accuracy: 0.7333\n",
      "Epoch 90/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.3635e-05 - accuracy: 1.0000 - val_loss: 2.7879 - val_accuracy: 0.7429\n",
      "Epoch 91/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.0696e-05 - accuracy: 1.0000 - val_loss: 2.8028 - val_accuracy: 0.7429\n",
      "Epoch 92/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.8271e-05 - accuracy: 1.0000 - val_loss: 2.8201 - val_accuracy: 0.7429\n",
      "Epoch 93/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.5547e-05 - accuracy: 1.0000 - val_loss: 2.8310 - val_accuracy: 0.7429\n",
      "Epoch 94/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.2961e-05 - accuracy: 1.0000 - val_loss: 2.8471 - val_accuracy: 0.7429\n",
      "Epoch 95/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.0778e-05 - accuracy: 1.0000 - val_loss: 2.8624 - val_accuracy: 0.7429\n",
      "Epoch 96/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.8531e-05 - accuracy: 1.0000 - val_loss: 2.8713 - val_accuracy: 0.7429\n",
      "Epoch 97/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.6552e-05 - accuracy: 1.0000 - val_loss: 2.8879 - val_accuracy: 0.7429\n",
      "Epoch 98/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.4646e-05 - accuracy: 1.0000 - val_loss: 2.9052 - val_accuracy: 0.7429\n",
      "Epoch 99/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.2800e-05 - accuracy: 1.0000 - val_loss: 2.9185 - val_accuracy: 0.7429\n",
      "Epoch 100/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.1051e-05 - accuracy: 1.0000 - val_loss: 2.9313 - val_accuracy: 0.7429\n",
      "Epoch 101/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.9343e-05 - accuracy: 1.0000 - val_loss: 2.9465 - val_accuracy: 0.7429\n",
      "Epoch 102/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.7918e-05 - accuracy: 1.0000 - val_loss: 2.9588 - val_accuracy: 0.7429\n",
      "Epoch 103/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.6429e-05 - accuracy: 1.0000 - val_loss: 2.9744 - val_accuracy: 0.7429\n",
      "Epoch 104/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.5098e-05 - accuracy: 1.0000 - val_loss: 2.9853 - val_accuracy: 0.7429\n",
      "Epoch 105/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.3811e-05 - accuracy: 1.0000 - val_loss: 2.9971 - val_accuracy: 0.7429\n",
      "Epoch 106/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.2529e-05 - accuracy: 1.0000 - val_loss: 3.0148 - val_accuracy: 0.7429\n",
      "Epoch 107/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.1373e-05 - accuracy: 1.0000 - val_loss: 3.0262 - val_accuracy: 0.7429\n",
      "Epoch 108/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.0401e-05 - accuracy: 1.0000 - val_loss: 3.0401 - val_accuracy: 0.7429\n",
      "Epoch 109/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.9323e-05 - accuracy: 1.0000 - val_loss: 3.0557 - val_accuracy: 0.7429\n",
      "Epoch 110/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.8403e-05 - accuracy: 1.0000 - val_loss: 3.0657 - val_accuracy: 0.7429\n",
      "Epoch 111/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.7375e-05 - accuracy: 1.0000 - val_loss: 3.0815 - val_accuracy: 0.7429\n",
      "Epoch 112/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.6543e-05 - accuracy: 1.0000 - val_loss: 3.0928 - val_accuracy: 0.7429\n",
      "Epoch 113/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.5704e-05 - accuracy: 1.0000 - val_loss: 3.1081 - val_accuracy: 0.7429\n",
      "Epoch 114/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4957e-05 - accuracy: 1.0000 - val_loss: 3.1223 - val_accuracy: 0.7429\n",
      "Epoch 115/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.4136e-05 - accuracy: 1.0000 - val_loss: 3.1342 - val_accuracy: 0.7429\n",
      "Epoch 116/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.3389e-05 - accuracy: 1.0000 - val_loss: 3.1503 - val_accuracy: 0.7429\n",
      "Epoch 117/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2719e-05 - accuracy: 1.0000 - val_loss: 3.1647 - val_accuracy: 0.7429\n",
      "Epoch 118/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.2103e-05 - accuracy: 1.0000 - val_loss: 3.1772 - val_accuracy: 0.7429\n",
      "Epoch 119/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1422e-05 - accuracy: 1.0000 - val_loss: 3.1908 - val_accuracy: 0.7429\n",
      "Epoch 120/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0796e-05 - accuracy: 1.0000 - val_loss: 3.2051 - val_accuracy: 0.7429\n",
      "Epoch 121/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.0184e-05 - accuracy: 1.0000 - val_loss: 3.2205 - val_accuracy: 0.7429\n",
      "Epoch 122/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.6493e-06 - accuracy: 1.0000 - val_loss: 3.2342 - val_accuracy: 0.7429\n",
      "Epoch 123/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.1176e-06 - accuracy: 1.0000 - val_loss: 3.2492 - val_accuracy: 0.7429\n",
      "Epoch 124/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.6368e-06 - accuracy: 1.0000 - val_loss: 3.2609 - val_accuracy: 0.7429\n",
      "Epoch 125/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.1700e-06 - accuracy: 1.0000 - val_loss: 3.2756 - val_accuracy: 0.7429\n",
      "Epoch 126/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.7390e-06 - accuracy: 1.0000 - val_loss: 3.2898 - val_accuracy: 0.7429\n",
      "Epoch 127/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.3725e-06 - accuracy: 1.0000 - val_loss: 3.3034 - val_accuracy: 0.7429\n",
      "Epoch 128/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.9757e-06 - accuracy: 1.0000 - val_loss: 3.3177 - val_accuracy: 0.7429\n",
      "Epoch 129/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.6191e-06 - accuracy: 1.0000 - val_loss: 3.3295 - val_accuracy: 0.7429\n",
      "Epoch 130/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 6.2680e-06 - accuracy: 1.0000 - val_loss: 3.3459 - val_accuracy: 0.7429\n",
      "Epoch 131/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.9592e-06 - accuracy: 1.0000 - val_loss: 3.3550 - val_accuracy: 0.7429\n",
      "Epoch 132/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.6272e-06 - accuracy: 1.0000 - val_loss: 3.3694 - val_accuracy: 0.7429\n",
      "Epoch 133/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.3324e-06 - accuracy: 1.0000 - val_loss: 3.3842 - val_accuracy: 0.7429\n",
      "Epoch 134/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 5.0774e-06 - accuracy: 1.0000 - val_loss: 3.3936 - val_accuracy: 0.7429\n",
      "Epoch 135/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.8049e-06 - accuracy: 1.0000 - val_loss: 3.4065 - val_accuracy: 0.7429\n",
      "Epoch 136/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.5748e-06 - accuracy: 1.0000 - val_loss: 3.4196 - val_accuracy: 0.7429\n",
      "Epoch 137/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.3506e-06 - accuracy: 1.0000 - val_loss: 3.4327 - val_accuracy: 0.7429\n",
      "Epoch 138/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 4.1160e-06 - accuracy: 1.0000 - val_loss: 3.4457 - val_accuracy: 0.7429\n",
      "Epoch 139/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.9136e-06 - accuracy: 1.0000 - val_loss: 3.4608 - val_accuracy: 0.7429\n",
      "Epoch 140/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.7270e-06 - accuracy: 1.0000 - val_loss: 3.4722 - val_accuracy: 0.7429\n",
      "Epoch 141/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.5381e-06 - accuracy: 1.0000 - val_loss: 3.4856 - val_accuracy: 0.7429\n",
      "Epoch 142/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.3625e-06 - accuracy: 1.0000 - val_loss: 3.4974 - val_accuracy: 0.7429\n",
      "Epoch 143/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.2224e-06 - accuracy: 1.0000 - val_loss: 3.5098 - val_accuracy: 0.7429\n",
      "Epoch 144/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 3.0329e-06 - accuracy: 1.0000 - val_loss: 3.5211 - val_accuracy: 0.7429\n",
      "Epoch 145/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.8897e-06 - accuracy: 1.0000 - val_loss: 3.5364 - val_accuracy: 0.7429\n",
      "Epoch 146/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.7535e-06 - accuracy: 1.0000 - val_loss: 3.5480 - val_accuracy: 0.7429\n",
      "Epoch 147/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.6038e-06 - accuracy: 1.0000 - val_loss: 3.5611 - val_accuracy: 0.7429\n",
      "Epoch 148/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.4883e-06 - accuracy: 1.0000 - val_loss: 3.5738 - val_accuracy: 0.7429\n",
      "Epoch 149/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.3589e-06 - accuracy: 1.0000 - val_loss: 3.5837 - val_accuracy: 0.7429\n",
      "Epoch 150/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 2.2501e-06 - accuracy: 1.0000 - val_loss: 3.5968 - val_accuracy: 0.7429\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Epoch 1/150\n",
      "85/85 [==============================] - 1s 3ms/step - loss: 0.7139 - accuracy: 0.5556 - val_loss: 0.6662 - val_accuracy: 0.6095\n",
      "Epoch 2/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.6927 - val_loss: 0.5874 - val_accuracy: 0.6476\n",
      "Epoch 3/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7896 - val_loss: 0.5123 - val_accuracy: 0.7714\n",
      "Epoch 4/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8274 - val_loss: 0.4808 - val_accuracy: 0.7810\n",
      "Epoch 5/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8652 - val_loss: 0.4613 - val_accuracy: 0.7810\n",
      "Epoch 6/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2902 - accuracy: 0.8889 - val_loss: 0.4627 - val_accuracy: 0.7810\n",
      "Epoch 7/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.9007 - val_loss: 0.4637 - val_accuracy: 0.7905\n",
      "Epoch 8/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9243 - val_loss: 0.4769 - val_accuracy: 0.8000\n",
      "Epoch 9/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9314 - val_loss: 0.4810 - val_accuracy: 0.8000\n",
      "Epoch 10/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9433 - val_loss: 0.4950 - val_accuracy: 0.7810\n",
      "Epoch 11/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1555 - accuracy: 0.9574 - val_loss: 0.5138 - val_accuracy: 0.7810\n",
      "Epoch 12/150\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.1398 - accuracy: 0.9551 - val_loss: 0.5368 - val_accuracy: 0.7810\n",
      "Epoch 13/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9693 - val_loss: 0.5623 - val_accuracy: 0.7714\n",
      "Epoch 14/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1057 - accuracy: 0.9787 - val_loss: 0.5862 - val_accuracy: 0.7619\n",
      "Epoch 15/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9764 - val_loss: 0.6043 - val_accuracy: 0.7810\n",
      "Epoch 16/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9835 - val_loss: 0.6205 - val_accuracy: 0.7810\n",
      "Epoch 17/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9858 - val_loss: 0.6574 - val_accuracy: 0.7810\n",
      "Epoch 18/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9858 - val_loss: 0.6673 - val_accuracy: 0.7810\n",
      "Epoch 19/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9929 - val_loss: 0.7092 - val_accuracy: 0.7905\n",
      "Epoch 20/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9929 - val_loss: 0.7035 - val_accuracy: 0.7905\n",
      "Epoch 21/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9953 - val_loss: 0.7318 - val_accuracy: 0.7810\n",
      "Epoch 22/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9953 - val_loss: 0.7629 - val_accuracy: 0.7905\n",
      "Epoch 23/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9953 - val_loss: 0.7819 - val_accuracy: 0.8000\n",
      "Epoch 24/150\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 0.0247 - accuracy: 0.9953 - val_loss: 0.8180 - val_accuracy: 0.7905\n",
      "Epoch 25/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9976 - val_loss: 0.8238 - val_accuracy: 0.8000\n",
      "Epoch 26/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9976 - val_loss: 0.8672 - val_accuracy: 0.8000\n",
      "Epoch 27/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9976 - val_loss: 0.8883 - val_accuracy: 0.8000\n",
      "Epoch 28/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9976 - val_loss: 0.9042 - val_accuracy: 0.8000\n",
      "Epoch 29/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9976 - val_loss: 0.9251 - val_accuracy: 0.7810\n",
      "Epoch 30/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 0.9417 - val_accuracy: 0.7905\n",
      "Epoch 31/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.9675 - val_accuracy: 0.7905\n",
      "Epoch 32/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.9933 - val_accuracy: 0.7905\n",
      "Epoch 33/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 1.0001 - val_accuracy: 0.7905\n",
      "Epoch 34/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 1.0144 - val_accuracy: 0.7905\n",
      "Epoch 35/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 1.0397 - val_accuracy: 0.7905\n",
      "Epoch 36/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 1.0511 - val_accuracy: 0.7905\n",
      "Epoch 37/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 1.0596 - val_accuracy: 0.8000\n",
      "Epoch 38/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 1.0655 - val_accuracy: 0.7905\n",
      "Epoch 39/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 1.0776 - val_accuracy: 0.7905\n",
      "Epoch 40/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 1.0889 - val_accuracy: 0.7905\n",
      "Epoch 41/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 1.1004 - val_accuracy: 0.7905\n",
      "Epoch 42/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 1.1089 - val_accuracy: 0.7905\n",
      "Epoch 43/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 1.1246 - val_accuracy: 0.7905\n",
      "Epoch 44/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 1.1443 - val_accuracy: 0.7905\n",
      "Epoch 45/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 1.1587 - val_accuracy: 0.7905\n",
      "Epoch 46/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 1.1717 - val_accuracy: 0.7905\n",
      "Epoch 47/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 1.1845 - val_accuracy: 0.7905\n",
      "Epoch 48/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 1.1892 - val_accuracy: 0.7905\n",
      "Epoch 49/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 1.2016 - val_accuracy: 0.7905\n",
      "Epoch 50/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 1.2159 - val_accuracy: 0.7905\n",
      "Epoch 51/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 1.2244 - val_accuracy: 0.7905\n",
      "Epoch 52/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 1.2291 - val_accuracy: 0.7905\n",
      "Epoch 53/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 1.2427 - val_accuracy: 0.7905\n",
      "Epoch 54/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 1.2576 - val_accuracy: 0.7905\n",
      "Epoch 55/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 1.2721 - val_accuracy: 0.7905\n",
      "Epoch 56/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 1.2835 - val_accuracy: 0.7905\n",
      "Epoch 57/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 1.2933 - val_accuracy: 0.7905\n",
      "Epoch 58/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 1.3011 - val_accuracy: 0.7905\n",
      "Epoch 59/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 1.2820 - val_accuracy: 0.8000\n",
      "Epoch 60/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 1.2760 - val_accuracy: 0.8000\n",
      "Epoch 61/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 1.2957 - val_accuracy: 0.8000\n",
      "Epoch 62/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 1.3126 - val_accuracy: 0.8000\n",
      "Epoch 63/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 1.3268 - val_accuracy: 0.8000\n",
      "Epoch 64/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 1.3346 - val_accuracy: 0.8000\n",
      "Epoch 65/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 1.3427 - val_accuracy: 0.8000\n",
      "Epoch 66/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 1.3607 - val_accuracy: 0.8000\n",
      "Epoch 67/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 1.3681 - val_accuracy: 0.8000\n",
      "Epoch 68/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 1.3742 - val_accuracy: 0.8000\n",
      "Epoch 69/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 1.3818 - val_accuracy: 0.8000\n",
      "Epoch 70/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 1.3902 - val_accuracy: 0.8000\n",
      "Epoch 71/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 1.4012 - val_accuracy: 0.8000\n",
      "Epoch 72/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9976 - val_loss: 1.4097 - val_accuracy: 0.8000\n",
      "Epoch 73/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9976 - val_loss: 1.4214 - val_accuracy: 0.8000\n",
      "Epoch 74/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 1.4346 - val_accuracy: 0.8000\n",
      "Epoch 75/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9976 - val_loss: 1.4344 - val_accuracy: 0.8000\n",
      "Epoch 76/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9976 - val_loss: 1.4154 - val_accuracy: 0.7810\n",
      "Epoch 77/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 1.4127 - val_accuracy: 0.7905\n",
      "Epoch 78/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 1.3997 - val_accuracy: 0.8000\n",
      "Epoch 79/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 1.4058 - val_accuracy: 0.8095\n",
      "Epoch 80/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 1.4079 - val_accuracy: 0.8000\n",
      "Epoch 81/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.9976 - val_loss: 1.4169 - val_accuracy: 0.8000\n",
      "Epoch 82/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9976 - val_loss: 1.4274 - val_accuracy: 0.8000\n",
      "Epoch 83/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 1.4372 - val_accuracy: 0.8000\n",
      "Epoch 84/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.9976 - val_loss: 1.4494 - val_accuracy: 0.8000\n",
      "Epoch 85/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9976 - val_loss: 1.4637 - val_accuracy: 0.8000\n",
      "Epoch 86/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9976 - val_loss: 1.4694 - val_accuracy: 0.8000\n",
      "Epoch 87/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9976 - val_loss: 1.4759 - val_accuracy: 0.8000\n",
      "Epoch 88/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9976 - val_loss: 1.4842 - val_accuracy: 0.8000\n",
      "Epoch 89/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9976 - val_loss: 1.4950 - val_accuracy: 0.8000\n",
      "Epoch 90/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9976 - val_loss: 1.5016 - val_accuracy: 0.8000\n",
      "Epoch 91/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9976 - val_loss: 1.5128 - val_accuracy: 0.8000\n",
      "Epoch 92/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9976 - val_loss: 1.5194 - val_accuracy: 0.8000\n",
      "Epoch 93/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9976 - val_loss: 1.5187 - val_accuracy: 0.8000\n",
      "Epoch 94/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9976 - val_loss: 1.5340 - val_accuracy: 0.8000\n",
      "Epoch 95/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9976 - val_loss: 1.5344 - val_accuracy: 0.8000\n",
      "Epoch 96/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9976 - val_loss: 1.5444 - val_accuracy: 0.8000\n",
      "Epoch 97/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.9976 - val_loss: 1.5501 - val_accuracy: 0.8000\n",
      "Epoch 98/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.9976 - val_loss: 1.5641 - val_accuracy: 0.8000\n",
      "Epoch 99/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.9976 - val_loss: 1.5633 - val_accuracy: 0.8000\n",
      "Epoch 100/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9976 - val_loss: 1.5708 - val_accuracy: 0.8000\n",
      "Epoch 101/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9976 - val_loss: 1.5783 - val_accuracy: 0.8000\n",
      "Epoch 102/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9976 - val_loss: 1.5886 - val_accuracy: 0.8000\n",
      "Epoch 103/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9976 - val_loss: 1.5998 - val_accuracy: 0.8000\n",
      "Epoch 104/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9976 - val_loss: 1.6044 - val_accuracy: 0.8000\n",
      "Epoch 105/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9976 - val_loss: 1.6064 - val_accuracy: 0.8000\n",
      "Epoch 106/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9976 - val_loss: 1.6195 - val_accuracy: 0.8000\n",
      "Epoch 107/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9976 - val_loss: 1.6290 - val_accuracy: 0.8000\n",
      "Epoch 108/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9976 - val_loss: 1.6369 - val_accuracy: 0.8000\n",
      "Epoch 109/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9976 - val_loss: 1.6408 - val_accuracy: 0.8000\n",
      "Epoch 110/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9976 - val_loss: 1.6504 - val_accuracy: 0.8000\n",
      "Epoch 111/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9976 - val_loss: 1.6587 - val_accuracy: 0.8000\n",
      "Epoch 112/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9976 - val_loss: 1.6671 - val_accuracy: 0.8000\n",
      "Epoch 113/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.9976 - val_loss: 1.6739 - val_accuracy: 0.8000\n",
      "Epoch 114/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.9976 - val_loss: 1.6834 - val_accuracy: 0.8000\n",
      "Epoch 115/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.9976 - val_loss: 1.6931 - val_accuracy: 0.8000\n",
      "Epoch 116/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.9976 - val_loss: 1.7041 - val_accuracy: 0.8095\n",
      "Epoch 117/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.9976 - val_loss: 1.7087 - val_accuracy: 0.8000\n",
      "Epoch 118/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9976 - val_loss: 1.7151 - val_accuracy: 0.8000\n",
      "Epoch 119/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9976 - val_loss: 1.7231 - val_accuracy: 0.8000\n",
      "Epoch 120/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9976 - val_loss: 1.7349 - val_accuracy: 0.8000\n",
      "Epoch 121/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9976 - val_loss: 1.7434 - val_accuracy: 0.8000\n",
      "Epoch 122/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9976 - val_loss: 1.7511 - val_accuracy: 0.8000\n",
      "Epoch 123/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.9976 - val_loss: 1.7593 - val_accuracy: 0.8000\n",
      "Epoch 124/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.9976 - val_loss: 1.7688 - val_accuracy: 0.8000\n",
      "Epoch 125/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.9976 - val_loss: 1.7819 - val_accuracy: 0.8000\n",
      "Epoch 126/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9976 - val_loss: 1.7911 - val_accuracy: 0.8000\n",
      "Epoch 127/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9976 - val_loss: 1.8000 - val_accuracy: 0.8000\n",
      "Epoch 128/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9976 - val_loss: 1.8026 - val_accuracy: 0.8000\n",
      "Epoch 129/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9976 - val_loss: 1.8148 - val_accuracy: 0.8000\n",
      "Epoch 130/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9976 - val_loss: 1.8242 - val_accuracy: 0.8000\n",
      "Epoch 131/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9976 - val_loss: 1.8366 - val_accuracy: 0.8000\n",
      "Epoch 132/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9976 - val_loss: 1.8461 - val_accuracy: 0.8000\n",
      "Epoch 133/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9976 - val_loss: 1.8550 - val_accuracy: 0.8000\n",
      "Epoch 134/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8627 - val_accuracy: 0.8000\n",
      "Epoch 135/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8733 - val_accuracy: 0.8000\n",
      "Epoch 136/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8792 - val_accuracy: 0.8000\n",
      "Epoch 137/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8876 - val_accuracy: 0.8095\n",
      "Epoch 138/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8990 - val_accuracy: 0.8000\n",
      "Epoch 139/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9069 - val_accuracy: 0.8000\n",
      "Epoch 140/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9159 - val_accuracy: 0.8000\n",
      "Epoch 141/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9208 - val_accuracy: 0.8095\n",
      "Epoch 142/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9320 - val_accuracy: 0.8095\n",
      "Epoch 143/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9375 - val_accuracy: 0.8095\n",
      "Epoch 144/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9443 - val_accuracy: 0.8095\n",
      "Epoch 145/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9568 - val_accuracy: 0.8095\n",
      "Epoch 146/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9614 - val_accuracy: 0.8000\n",
      "Epoch 147/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9703 - val_accuracy: 0.8095\n",
      "Epoch 148/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9783 - val_accuracy: 0.8095\n",
      "Epoch 149/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9889 - val_accuracy: 0.8095\n",
      "Epoch 150/150\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9961 - val_accuracy: 0.8095\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.79      0.79       264\n",
      "         1.0       0.79      0.79      0.79       264\n",
      "\n",
      "    accuracy                           0.79       528\n",
      "   macro avg       0.79      0.79      0.79       528\n",
      "weighted avg       0.79      0.79      0.79       528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.utils import np_utils\n",
    "\n",
    "data = np.loadtxt(\"C:/Users/franu/Downloads/RedesNeuronales/Actividad1/misterious_data_1.txt\") \n",
    "x = data[:,1:]\n",
    "y = data[:,0]\n",
    "\n",
    "y[y == 1] = 0\n",
    "y[y == 2] = 1\n",
    "\n",
    "#targets = data.target_names\n",
    "n_clases = len(np.unique(y))\n",
    "\n",
    "#features = data.feature_names\n",
    "n_features = x.shape[1]\n",
    "\n",
    "# Define MLP model\n",
    "clf = Sequential()\n",
    "clf.add(Dense(10, input_dim=n_features, activation='relu'))\n",
    "clf.add(Dense(10, activation='relu'))\n",
    "clf.add(Dense(1, activation='sigmoid')) # for 2-class problems, use clf.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Evaluate model\n",
    "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "\n",
    "cv_y_test = []\n",
    "cv_y_pred = []\n",
    "\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "\n",
    "    x_train = x[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "    #y_train_categorical = np_utils.to_categorical(y_train)\n",
    "\n",
    "    x_test = x[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "    #y_test_categorical = np_utils.to_categorical(y_test)\n",
    "\n",
    "    # Training phase\n",
    "    clf_cv = Sequential()\n",
    "    clf_cv.add(Dense(10, input_dim=n_features, activation='relu'))\n",
    "    clf_cv.add(Dense(10, activation='relu'))\n",
    "    clf_cv.add(Dense(1, activation='sigmoid'))\n",
    "    clf_cv.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    clf_cv.fit(x_train, y_train, validation_data= (x_test, y_test), epochs=150, batch_size=5)    \n",
    "\n",
    "    # Test phase\n",
    "    x_test = x[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "    y_pred = clf_cv.predict(x_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int) \n",
    "\n",
    "    cv_y_test.append(y_test)\n",
    "    cv_y_pred.append(y_pred)\n",
    "\n",
    "\n",
    "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ajusta un modelo perceptrón multicapa para este otro conjunto de datos(misterious_data_4) de cuatro clases y evalúa su rendimiento con validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.98      1.00      0.99        64\n",
      "         2.0       1.00      1.00      1.00        65\n",
      "         3.0       0.88      0.92      0.90        65\n",
      "         4.0       0.92      0.86      0.89        65\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.95      0.95      0.95       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"C:/Users/franu/Downloads/RedesNeuronales/Actividad1/misterious_data_4.txt\") \n",
    "x = data[:,1:]\n",
    "y = data[:,0]\n",
    "\n",
    "# Train MLP classifier with all the available observations\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=10000)  # hidden_layer_sizes controls the number of neurons of each hidden layer.\n",
    "clf.fit(x, y)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "n_splits=5\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle = True)\n",
    "\n",
    "cv_y_test = []\n",
    "cv_y_pred = []\n",
    "\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "\n",
    "    # Training phase\n",
    "    x_train = x[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    clf_i = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=10000)\n",
    "    clf_i.fit(x_train, y_train)\n",
    "\n",
    "    # Test phase\n",
    "    x_test = x[test_index, :]\n",
    "    y_test = y[test_index]    \n",
    "    y_pred = clf_i.predict(x_test)\n",
    "\n",
    "    cv_y_test.append(y_test)\n",
    "    cv_y_pred.append(y_pred)\n",
    "\n",
    "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n",
      "Epoch 1/150\n",
      "52/52 [==============================] - 1s 1ms/step - loss: 0.9567 - accuracy: 0.4903\n",
      "Epoch 2/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6346 - accuracy: 0.6911\n",
      "Epoch 3/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7606\n",
      "Epoch 4/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2833 - accuracy: 0.9421\n",
      "Epoch 5/150\n",
      "52/52 [==============================] - 0s 991us/step - loss: 0.1909 - accuracy: 0.9575\n",
      "Epoch 6/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9498\n",
      "Epoch 7/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.9537\n",
      "Epoch 8/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9653\n",
      "Epoch 9/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0835 - accuracy: 0.9730\n",
      "Epoch 10/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0681 - accuracy: 0.9807\n",
      "Epoch 11/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9768\n",
      "Epoch 12/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9807\n",
      "Epoch 13/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.9691\n",
      "Epoch 14/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9807\n",
      "Epoch 15/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9614\n",
      "Epoch 16/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9730\n",
      "Epoch 17/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9846\n",
      "Epoch 18/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9768\n",
      "Epoch 19/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 0.9807\n",
      "Epoch 20/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9768\n",
      "Epoch 21/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9768\n",
      "Epoch 22/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9884\n",
      "Epoch 23/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 0.9884\n",
      "Epoch 24/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.9884\n",
      "Epoch 25/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9884\n",
      "Epoch 26/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 0.9807\n",
      "Epoch 27/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9730\n",
      "Epoch 28/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9614\n",
      "Epoch 29/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9807\n",
      "Epoch 30/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9768\n",
      "Epoch 31/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9846\n",
      "Epoch 32/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9884\n",
      "Epoch 33/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9884\n",
      "Epoch 34/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9884\n",
      "Epoch 35/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9884\n",
      "Epoch 36/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9923\n",
      "Epoch 37/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0409 - accuracy: 0.9807\n",
      "Epoch 38/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 0.9846\n",
      "Epoch 39/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0345 - accuracy: 0.9884\n",
      "Epoch 40/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9923\n",
      "Epoch 41/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9884\n",
      "Epoch 42/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9884\n",
      "Epoch 43/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 0.9961\n",
      "Epoch 44/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 0.9961\n",
      "Epoch 45/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9768\n",
      "Epoch 46/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9923\n",
      "Epoch 47/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9884\n",
      "Epoch 48/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 0.9961\n",
      "Epoch 49/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.9961\n",
      "Epoch 51/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 52/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 54/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9846\n",
      "Epoch 55/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 0.9923\n",
      "Epoch 56/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 0.9961\n",
      "Epoch 60/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9807\n",
      "Epoch 61/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9730\n",
      "Epoch 62/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 0.9961\n",
      "Epoch 63/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9846\n",
      "Epoch 64/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9884\n",
      "Epoch 65/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9923\n",
      "Epoch 66/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0084 - accuracy: 0.9961\n",
      "Epoch 74/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 0.9961\n",
      "Epoch 75/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 9.8572e-04 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 9.5110e-04 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 8.3813e-04 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 8.4358e-04 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 8.6051e-04 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 7.8893e-04 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 7.4117e-04 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 8.9886e-04 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 7.8826e-04 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 7.2341e-04 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 6.8944e-04 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 6.4441e-04 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 6.8868e-04 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 9.8119e-04 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 7.8589e-04 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 5.7530e-04 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 6.2221e-04 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 5.3298e-04 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 5.5372e-04 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 4.8501e-04 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 5.3327e-04 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 5.5802e-04 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 4.5757e-04 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 4.2830e-04 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 4.0209e-04 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 3.9772e-04 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 4.4642e-04 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.1196e-04 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.4043e-04 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.5486e-04 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.3688e-04 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.3379e-04 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.4317e-04 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.3045e-04 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0928e-04 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8214e-04 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.2666e-04 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7489e-04 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4276e-04 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8182e-04 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5722e-04 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5654e-04 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3989e-04 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.4965e-04 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.3042e-04 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.3320e-04 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.9662e-04 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9423e-04 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.0765e-04 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.2359e-04 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.9728e-04 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.7034e-04 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.6360e-04 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.5600e-04 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.5697e-04 - accuracy: 1.0000\n",
      "Epoch 1/150\n",
      "42/42 [==============================] - 1s 7ms/step - loss: 1.0218 - accuracy: 0.5749 - val_loss: 0.4617 - val_accuracy: 0.7885\n",
      "Epoch 2/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 0.8986 - val_loss: 0.2472 - val_accuracy: 0.8846\n",
      "Epoch 3/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1796 - accuracy: 0.9565 - val_loss: 0.1833 - val_accuracy: 0.9038\n",
      "Epoch 4/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1904 - accuracy: 0.9227 - val_loss: 0.2895 - val_accuracy: 0.8846\n",
      "Epoch 5/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1096 - accuracy: 0.9758 - val_loss: 0.1641 - val_accuracy: 0.9231\n",
      "Epoch 6/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 0.9758 - val_loss: 0.1563 - val_accuracy: 0.8846\n",
      "Epoch 7/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9855 - val_loss: 0.2498 - val_accuracy: 0.8846\n",
      "Epoch 8/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9807 - val_loss: 0.1762 - val_accuracy: 0.9231\n",
      "Epoch 9/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9855 - val_loss: 0.1936 - val_accuracy: 0.9231\n",
      "Epoch 10/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9952 - val_loss: 0.1615 - val_accuracy: 0.9231\n",
      "Epoch 11/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9903 - val_loss: 0.1713 - val_accuracy: 0.9231\n",
      "Epoch 12/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9855 - val_loss: 0.1846 - val_accuracy: 0.9038\n",
      "Epoch 13/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9903 - val_loss: 0.2718 - val_accuracy: 0.9038\n",
      "Epoch 14/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9855 - val_loss: 0.1716 - val_accuracy: 0.9231\n",
      "Epoch 15/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9855 - val_loss: 0.1740 - val_accuracy: 0.9231\n",
      "Epoch 16/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9903 - val_loss: 0.1523 - val_accuracy: 0.9231\n",
      "Epoch 17/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9903 - val_loss: 0.1698 - val_accuracy: 0.9038\n",
      "Epoch 18/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9807 - val_loss: 0.1825 - val_accuracy: 0.9231\n",
      "Epoch 19/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9710 - val_loss: 0.4962 - val_accuracy: 0.8846\n",
      "Epoch 20/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9855 - val_loss: 0.1991 - val_accuracy: 0.9231\n",
      "Epoch 21/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9903 - val_loss: 0.1919 - val_accuracy: 0.9231\n",
      "Epoch 22/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9952 - val_loss: 0.1923 - val_accuracy: 0.9231\n",
      "Epoch 23/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9952 - val_loss: 0.1970 - val_accuracy: 0.9231\n",
      "Epoch 24/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9231\n",
      "Epoch 25/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9231\n",
      "Epoch 26/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9423\n",
      "Epoch 27/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.9952 - val_loss: 0.1853 - val_accuracy: 0.9423\n",
      "Epoch 28/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9231\n",
      "Epoch 29/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9231\n",
      "Epoch 30/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9423\n",
      "Epoch 31/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9231\n",
      "Epoch 32/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9423\n",
      "Epoch 33/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9231\n",
      "Epoch 34/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9231\n",
      "Epoch 35/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9231\n",
      "Epoch 36/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 0.9231\n",
      "Epoch 37/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9231\n",
      "Epoch 38/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9231\n",
      "Epoch 39/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9231\n",
      "Epoch 40/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9231\n",
      "Epoch 41/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9231\n",
      "Epoch 42/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9231\n",
      "Epoch 43/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9231\n",
      "Epoch 44/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9231\n",
      "Epoch 45/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9231\n",
      "Epoch 46/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9423\n",
      "Epoch 47/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9231\n",
      "Epoch 48/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9231\n",
      "Epoch 49/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9231\n",
      "Epoch 50/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.9231\n",
      "Epoch 51/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9231\n",
      "Epoch 52/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9231\n",
      "Epoch 53/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9231\n",
      "Epoch 54/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2898 - val_accuracy: 0.9231\n",
      "Epoch 55/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9231\n",
      "Epoch 56/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9231\n",
      "Epoch 57/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9231\n",
      "Epoch 58/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9231\n",
      "Epoch 59/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9231\n",
      "Epoch 60/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9231\n",
      "Epoch 61/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9231\n",
      "Epoch 62/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9231\n",
      "Epoch 63/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9231\n",
      "Epoch 64/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9231\n",
      "Epoch 65/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9231\n",
      "Epoch 66/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9231\n",
      "Epoch 67/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9231\n",
      "Epoch 68/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.9231\n",
      "Epoch 69/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9231\n",
      "Epoch 70/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9231\n",
      "Epoch 71/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.8425e-04 - accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.9231\n",
      "Epoch 72/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.6114e-04 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9231\n",
      "Epoch 73/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.7108e-04 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9231\n",
      "Epoch 74/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.2442e-04 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9231\n",
      "Epoch 75/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 8.6340e-04 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9231\n",
      "Epoch 76/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.4143e-04 - accuracy: 1.0000 - val_loss: 0.3239 - val_accuracy: 0.9231\n",
      "Epoch 77/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 8.5696e-04 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.9231\n",
      "Epoch 78/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.5488e-04 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9231\n",
      "Epoch 79/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.0394e-04 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.9231\n",
      "Epoch 80/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.8393e-04 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.9231\n",
      "Epoch 81/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.1776e-04 - accuracy: 1.0000 - val_loss: 0.3056 - val_accuracy: 0.9231\n",
      "Epoch 82/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.2250e-04 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9231\n",
      "Epoch 83/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.2063e-04 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9231\n",
      "Epoch 84/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.5394e-04 - accuracy: 1.0000 - val_loss: 0.3224 - val_accuracy: 0.9231\n",
      "Epoch 85/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.5495e-04 - accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.9231\n",
      "Epoch 86/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.0039e-04 - accuracy: 1.0000 - val_loss: 0.3254 - val_accuracy: 0.9231\n",
      "Epoch 87/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.3266e-04 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9231\n",
      "Epoch 88/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.1895e-04 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9231\n",
      "Epoch 89/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.9737e-04 - accuracy: 1.0000 - val_loss: 0.3323 - val_accuracy: 0.9231\n",
      "Epoch 90/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.7723e-04 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9231\n",
      "Epoch 91/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.7342e-04 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9231\n",
      "Epoch 92/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.4901e-04 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.9231\n",
      "Epoch 93/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5052e-04 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9231\n",
      "Epoch 94/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2025e-04 - accuracy: 1.0000 - val_loss: 0.3254 - val_accuracy: 0.9231\n",
      "Epoch 95/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.0463e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9231\n",
      "Epoch 96/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.5108e-04 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9231\n",
      "Epoch 97/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.1750e-04 - accuracy: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9231\n",
      "Epoch 98/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.2022e-04 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9231\n",
      "Epoch 99/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 3.6284e-04 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9231\n",
      "Epoch 100/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 3.6659e-04 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.9231\n",
      "Epoch 101/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 3.5893e-04 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.9231\n",
      "Epoch 102/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 3.2396e-04 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9231\n",
      "Epoch 103/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 3.2941e-04 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9231\n",
      "Epoch 104/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 3.1438e-04 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.9231\n",
      "Epoch 105/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.0488e-04 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9231\n",
      "Epoch 106/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.9422e-04 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.9231\n",
      "Epoch 107/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.1054e-04 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.9231\n",
      "Epoch 108/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.5760e-04 - accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.9231\n",
      "Epoch 109/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.8450e-04 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9231\n",
      "Epoch 110/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.6707e-04 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9231\n",
      "Epoch 111/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.4683e-04 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9231\n",
      "Epoch 112/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.4354e-04 - accuracy: 1.0000 - val_loss: 0.3380 - val_accuracy: 0.9231\n",
      "Epoch 113/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.4159e-04 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.9231\n",
      "Epoch 114/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.4683e-04 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9231\n",
      "Epoch 115/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.1731e-04 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.9231\n",
      "Epoch 116/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.2099e-04 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 0.9231\n",
      "Epoch 117/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.1003e-04 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9231\n",
      "Epoch 118/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.0325e-04 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.9231\n",
      "Epoch 119/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.0438e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9231\n",
      "Epoch 120/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.9492e-04 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9231\n",
      "Epoch 121/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.8333e-04 - accuracy: 1.0000 - val_loss: 0.3670 - val_accuracy: 0.9231\n",
      "Epoch 122/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.8961e-04 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.9231\n",
      "Epoch 123/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.8461e-04 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9231\n",
      "Epoch 124/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.6147e-04 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.9231\n",
      "Epoch 125/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.8825e-04 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.9231\n",
      "Epoch 126/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.7080e-04 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.9231\n",
      "Epoch 127/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5608e-04 - accuracy: 1.0000 - val_loss: 0.3655 - val_accuracy: 0.9231\n",
      "Epoch 128/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5147e-04 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9231\n",
      "Epoch 129/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.6206e-04 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.9231\n",
      "Epoch 130/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.8368e-04 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.9231\n",
      "Epoch 131/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.4814e-04 - accuracy: 1.0000 - val_loss: 0.3698 - val_accuracy: 0.9231\n",
      "Epoch 132/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.3284e-04 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.9231\n",
      "Epoch 133/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.2925e-04 - accuracy: 1.0000 - val_loss: 0.3796 - val_accuracy: 0.9231\n",
      "Epoch 134/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.3621e-04 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9231\n",
      "Epoch 135/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.3446e-04 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9231\n",
      "Epoch 136/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.2667e-04 - accuracy: 1.0000 - val_loss: 0.3796 - val_accuracy: 0.9231\n",
      "Epoch 137/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.4310e-04 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9231\n",
      "Epoch 138/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.2403e-04 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.9231\n",
      "Epoch 139/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.1534e-04 - accuracy: 1.0000 - val_loss: 0.3745 - val_accuracy: 0.9231\n",
      "Epoch 140/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.1367e-04 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.9231\n",
      "Epoch 141/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.1181e-04 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.9231\n",
      "Epoch 142/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.1045e-04 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9231\n",
      "Epoch 143/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0227e-04 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9231\n",
      "Epoch 144/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 9.4303e-05 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.9231\n",
      "Epoch 145/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 9.5938e-05 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9231\n",
      "Epoch 146/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 9.0127e-05 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9231\n",
      "Epoch 147/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.9975e-05 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9231\n",
      "Epoch 148/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 8.8859e-05 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9231\n",
      "Epoch 149/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 8.9672e-05 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9231\n",
      "Epoch 150/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 8.3372e-05 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9231\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/150\n",
      "42/42 [==============================] - 1s 7ms/step - loss: 0.8108 - accuracy: 0.7101 - val_loss: 0.3690 - val_accuracy: 0.8846\n",
      "Epoch 2/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8696 - val_loss: 0.2137 - val_accuracy: 0.9615\n",
      "Epoch 3/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2541 - accuracy: 0.8986 - val_loss: 0.1544 - val_accuracy: 0.9615\n",
      "Epoch 4/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9372 - val_loss: 0.1553 - val_accuracy: 0.9615\n",
      "Epoch 5/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1691 - accuracy: 0.9275 - val_loss: 0.1095 - val_accuracy: 0.9808\n",
      "Epoch 6/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1553 - accuracy: 0.9275 - val_loss: 0.1124 - val_accuracy: 0.9808\n",
      "Epoch 7/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9614 - val_loss: 0.1324 - val_accuracy: 0.9231\n",
      "Epoch 8/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 0.9227 - val_loss: 0.0779 - val_accuracy: 0.9808\n",
      "Epoch 9/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.9565 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
      "Epoch 10/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.9469 - val_loss: 0.0641 - val_accuracy: 0.9808\n",
      "Epoch 11/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.9565 - val_loss: 0.0770 - val_accuracy: 0.9615\n",
      "Epoch 12/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9662 - val_loss: 0.0795 - val_accuracy: 0.9615\n",
      "Epoch 13/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.9614 - val_loss: 0.0591 - val_accuracy: 0.9615\n",
      "Epoch 14/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1099 - accuracy: 0.9614 - val_loss: 0.0660 - val_accuracy: 0.9808\n",
      "Epoch 15/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.9710 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "Epoch 16/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.9614 - val_loss: 0.0711 - val_accuracy: 0.9615\n",
      "Epoch 17/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9662 - val_loss: 0.0650 - val_accuracy: 0.9808\n",
      "Epoch 18/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.9710 - val_loss: 0.0440 - val_accuracy: 0.9808\n",
      "Epoch 19/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9758 - val_loss: 0.0424 - val_accuracy: 0.9808\n",
      "Epoch 20/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9903 - val_loss: 0.0418 - val_accuracy: 0.9808\n",
      "Epoch 21/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9903 - val_loss: 0.0425 - val_accuracy: 0.9808\n",
      "Epoch 22/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9903 - val_loss: 0.0377 - val_accuracy: 0.9808\n",
      "Epoch 23/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9903 - val_loss: 0.0491 - val_accuracy: 0.9808\n",
      "Epoch 24/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9903 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9710 - val_loss: 0.0662 - val_accuracy: 0.9615\n",
      "Epoch 26/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9758 - val_loss: 0.1015 - val_accuracy: 0.9423\n",
      "Epoch 27/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9758 - val_loss: 0.0438 - val_accuracy: 0.9808\n",
      "Epoch 28/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9807 - val_loss: 0.0486 - val_accuracy: 0.9808\n",
      "Epoch 29/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.9855 - val_loss: 0.0530 - val_accuracy: 0.9808\n",
      "Epoch 30/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9758 - val_loss: 0.0464 - val_accuracy: 0.9808\n",
      "Epoch 31/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9903 - val_loss: 0.0550 - val_accuracy: 0.9808\n",
      "Epoch 32/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9807 - val_loss: 0.0823 - val_accuracy: 0.9615\n",
      "Epoch 33/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9758 - val_loss: 0.0482 - val_accuracy: 0.9808\n",
      "Epoch 34/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9903 - val_loss: 0.0410 - val_accuracy: 0.9808\n",
      "Epoch 35/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.9807 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9855 - val_loss: 0.0401 - val_accuracy: 0.9808\n",
      "Epoch 37/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9903 - val_loss: 0.0479 - val_accuracy: 0.9808\n",
      "Epoch 38/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.9855 - val_loss: 0.0553 - val_accuracy: 0.9808\n",
      "Epoch 39/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9855 - val_loss: 0.0439 - val_accuracy: 0.9808\n",
      "Epoch 40/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9952 - val_loss: 0.0625 - val_accuracy: 0.9808\n",
      "Epoch 41/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9903 - val_loss: 0.0558 - val_accuracy: 0.9808\n",
      "Epoch 42/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9855 - val_loss: 0.0545 - val_accuracy: 0.9808\n",
      "Epoch 43/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9855 - val_loss: 0.0782 - val_accuracy: 0.9808\n",
      "Epoch 44/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 0.0889 - val_accuracy: 0.9615\n",
      "Epoch 45/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9855 - val_loss: 0.0534 - val_accuracy: 0.9808\n",
      "Epoch 46/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9855 - val_loss: 0.0498 - val_accuracy: 0.9615\n",
      "Epoch 47/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.0733 - val_accuracy: 0.9808\n",
      "Epoch 48/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9952 - val_loss: 0.0341 - val_accuracy: 0.9808\n",
      "Epoch 49/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 0.0386 - val_accuracy: 0.9808\n",
      "Epoch 50/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0964 - val_accuracy: 0.9615\n",
      "Epoch 51/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9855 - val_loss: 0.0435 - val_accuracy: 0.9615\n",
      "Epoch 52/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9903 - val_loss: 0.0543 - val_accuracy: 0.9808\n",
      "Epoch 53/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.0509 - val_accuracy: 0.9615\n",
      "Epoch 54/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9615\n",
      "Epoch 55/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.9903 - val_loss: 0.0702 - val_accuracy: 0.9808\n",
      "Epoch 56/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9615\n",
      "Epoch 57/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9952 - val_loss: 0.1648 - val_accuracy: 0.9615\n",
      "Epoch 58/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9903 - val_loss: 0.0910 - val_accuracy: 0.9808\n",
      "Epoch 59/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9808\n",
      "Epoch 60/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9615\n",
      "Epoch 61/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9903 - val_loss: 0.0477 - val_accuracy: 0.9615\n",
      "Epoch 62/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9952 - val_loss: 0.0827 - val_accuracy: 0.9808\n",
      "Epoch 63/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.0664 - val_accuracy: 0.9808\n",
      "Epoch 64/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9855 - val_loss: 0.1630 - val_accuracy: 0.9615\n",
      "Epoch 65/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9903 - val_loss: 0.0691 - val_accuracy: 0.9808\n",
      "Epoch 66/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9615\n",
      "Epoch 67/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.9952 - val_loss: 0.0695 - val_accuracy: 0.9808\n",
      "Epoch 68/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9808\n",
      "Epoch 69/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9808\n",
      "Epoch 70/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9808\n",
      "Epoch 71/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9808\n",
      "Epoch 72/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9615\n",
      "Epoch 73/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9808\n",
      "Epoch 74/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9808\n",
      "Epoch 75/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9808\n",
      "Epoch 76/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9808\n",
      "Epoch 77/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 0.9808\n",
      "Epoch 78/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9808\n",
      "Epoch 79/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9808\n",
      "Epoch 80/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9808\n",
      "Epoch 81/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9808\n",
      "Epoch 82/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9808\n",
      "Epoch 83/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9808\n",
      "Epoch 84/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9903 - val_loss: 0.0728 - val_accuracy: 0.9808\n",
      "Epoch 85/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9903 - val_loss: 0.0595 - val_accuracy: 0.9615\n",
      "Epoch 86/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 0.9615\n",
      "Epoch 87/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9758 - val_loss: 0.1562 - val_accuracy: 0.9615\n",
      "Epoch 88/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9614 - val_loss: 0.4662 - val_accuracy: 0.9231\n",
      "Epoch 89/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9517 - val_loss: 0.2259 - val_accuracy: 0.9038\n",
      "Epoch 90/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9758 - val_loss: 0.0983 - val_accuracy: 0.9615\n",
      "Epoch 91/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9808\n",
      "Epoch 92/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 0.9808\n",
      "Epoch 93/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9808\n",
      "Epoch 94/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 0.9808\n",
      "Epoch 95/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9808\n",
      "Epoch 96/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9808\n",
      "Epoch 97/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 0.9808\n",
      "Epoch 98/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9808\n",
      "Epoch 99/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9808\n",
      "Epoch 100/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0711 - val_accuracy: 0.9808\n",
      "Epoch 101/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9808\n",
      "Epoch 102/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9808\n",
      "Epoch 103/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9808\n",
      "Epoch 104/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9808\n",
      "Epoch 105/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9808\n",
      "Epoch 106/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9808\n",
      "Epoch 107/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9808\n",
      "Epoch 108/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9808\n",
      "Epoch 109/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9808\n",
      "Epoch 110/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9808\n",
      "Epoch 111/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9808\n",
      "Epoch 112/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9808\n",
      "Epoch 113/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9808\n",
      "Epoch 114/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9808\n",
      "Epoch 115/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9808\n",
      "Epoch 116/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9808\n",
      "Epoch 117/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9808\n",
      "Epoch 118/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9808\n",
      "Epoch 119/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9808\n",
      "Epoch 120/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9808\n",
      "Epoch 121/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9808\n",
      "Epoch 122/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9808\n",
      "Epoch 123/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9808\n",
      "Epoch 124/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.9847e-04 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9615\n",
      "Epoch 125/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9808\n",
      "Epoch 126/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.2184e-04 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9808\n",
      "Epoch 127/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.9456e-04 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9808\n",
      "Epoch 128/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.7465e-04 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9808\n",
      "Epoch 129/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.2048e-04 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9808\n",
      "Epoch 130/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.1062e-04 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9808\n",
      "Epoch 131/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.0144e-04 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9808\n",
      "Epoch 132/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.1624e-04 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9808\n",
      "Epoch 133/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.6385e-04 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9808\n",
      "Epoch 134/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.6864e-04 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9808\n",
      "Epoch 135/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.3408e-04 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9808\n",
      "Epoch 136/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.4562e-04 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9808\n",
      "Epoch 137/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.1400e-04 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9808\n",
      "Epoch 138/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.4653e-04 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9808\n",
      "Epoch 139/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.6250e-04 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9808\n",
      "Epoch 140/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.4148e-04 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9808\n",
      "Epoch 141/150\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 6.6044e-04 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9808\n",
      "Epoch 142/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.1708e-04 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9808\n",
      "Epoch 143/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.2540e-04 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9808\n",
      "Epoch 144/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.8355e-04 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9808\n",
      "Epoch 145/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.2762e-04 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9808\n",
      "Epoch 146/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.3633e-04 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9808\n",
      "Epoch 147/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.4358e-04 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9808\n",
      "Epoch 148/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.2831e-04 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9808\n",
      "Epoch 149/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.2018e-04 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9808\n",
      "Epoch 150/150\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 5.2968e-04 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9808\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/150\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.6517 - accuracy: 0.7391 - val_loss: 0.3569 - val_accuracy: 0.9231\n",
      "Epoch 2/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8937 - val_loss: 0.2388 - val_accuracy: 0.8846\n",
      "Epoch 3/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2259 - accuracy: 0.9179 - val_loss: 0.1651 - val_accuracy: 0.9423\n",
      "Epoch 4/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1907 - accuracy: 0.9275 - val_loss: 0.1388 - val_accuracy: 0.9423\n",
      "Epoch 5/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9324 - val_loss: 0.1635 - val_accuracy: 0.9038\n",
      "Epoch 6/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1523 - accuracy: 0.9227 - val_loss: 0.1005 - val_accuracy: 0.9615\n",
      "Epoch 7/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.9420 - val_loss: 0.0944 - val_accuracy: 0.9808\n",
      "Epoch 8/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.9662 - val_loss: 0.0994 - val_accuracy: 0.9615\n",
      "Epoch 9/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9710 - val_loss: 0.1020 - val_accuracy: 0.9808\n",
      "Epoch 10/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 0.9565 - val_loss: 0.0998 - val_accuracy: 0.9615\n",
      "Epoch 11/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9517 - val_loss: 0.0750 - val_accuracy: 0.9808\n",
      "Epoch 12/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9807 - val_loss: 0.1009 - val_accuracy: 0.9615\n",
      "Epoch 13/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9662 - val_loss: 0.0898 - val_accuracy: 0.9615\n",
      "Epoch 14/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.9710 - val_loss: 0.1158 - val_accuracy: 0.9231\n",
      "Epoch 15/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.9758 - val_loss: 0.0950 - val_accuracy: 0.9423\n",
      "Epoch 16/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9807 - val_loss: 0.0834 - val_accuracy: 0.9423\n",
      "Epoch 17/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9758 - val_loss: 0.0822 - val_accuracy: 0.9423\n",
      "Epoch 18/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9807 - val_loss: 0.0834 - val_accuracy: 0.9423\n",
      "Epoch 19/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9855 - val_loss: 0.0990 - val_accuracy: 0.9231\n",
      "Epoch 20/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9807 - val_loss: 0.1230 - val_accuracy: 0.9231\n",
      "Epoch 21/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9855 - val_loss: 0.0995 - val_accuracy: 0.9231\n",
      "Epoch 22/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.9903 - val_loss: 0.1001 - val_accuracy: 0.9231\n",
      "Epoch 23/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9903 - val_loss: 0.1043 - val_accuracy: 0.9231\n",
      "Epoch 24/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9855 - val_loss: 0.1198 - val_accuracy: 0.9231\n",
      "Epoch 25/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9758 - val_loss: 0.1165 - val_accuracy: 0.9231\n",
      "Epoch 26/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9807 - val_loss: 0.1960 - val_accuracy: 0.9423\n",
      "Epoch 27/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9807 - val_loss: 0.1237 - val_accuracy: 0.9231\n",
      "Epoch 28/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9903 - val_loss: 0.1504 - val_accuracy: 0.9423\n",
      "Epoch 29/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9855 - val_loss: 0.1232 - val_accuracy: 0.9615\n",
      "Epoch 30/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9952 - val_loss: 0.1483 - val_accuracy: 0.9231\n",
      "Epoch 31/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9855 - val_loss: 0.1262 - val_accuracy: 0.9615\n",
      "Epoch 32/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9952 - val_loss: 0.1329 - val_accuracy: 0.9231\n",
      "Epoch 33/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 0.1578 - val_accuracy: 0.9423\n",
      "Epoch 34/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9855 - val_loss: 0.2169 - val_accuracy: 0.9423\n",
      "Epoch 35/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9855 - val_loss: 0.1267 - val_accuracy: 0.9423\n",
      "Epoch 36/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9807 - val_loss: 0.2014 - val_accuracy: 0.9038\n",
      "Epoch 37/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9952 - val_loss: 0.1673 - val_accuracy: 0.9231\n",
      "Epoch 38/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.1394 - val_accuracy: 0.9231\n",
      "Epoch 39/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.1351 - val_accuracy: 0.9231\n",
      "Epoch 40/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9231\n",
      "Epoch 41/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9807 - val_loss: 0.1358 - val_accuracy: 0.9615\n",
      "Epoch 42/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.9903 - val_loss: 0.1490 - val_accuracy: 0.9231\n",
      "Epoch 43/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9615\n",
      "Epoch 44/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9231\n",
      "Epoch 45/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9952 - val_loss: 0.1638 - val_accuracy: 0.9231\n",
      "Epoch 46/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.9952 - val_loss: 0.1750 - val_accuracy: 0.9231\n",
      "Epoch 47/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9231\n",
      "Epoch 48/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.1662 - val_accuracy: 0.9231\n",
      "Epoch 49/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9423\n",
      "Epoch 50/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9038\n",
      "Epoch 51/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.1408 - val_accuracy: 0.9423\n",
      "Epoch 52/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.1766 - val_accuracy: 0.9231\n",
      "Epoch 53/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9231\n",
      "Epoch 54/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9231\n",
      "Epoch 55/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9231\n",
      "Epoch 56/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9423\n",
      "Epoch 57/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9231\n",
      "Epoch 58/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9231\n",
      "Epoch 59/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9231\n",
      "Epoch 60/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9423\n",
      "Epoch 61/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9423\n",
      "Epoch 62/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9231\n",
      "Epoch 63/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9423\n",
      "Epoch 64/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9423\n",
      "Epoch 65/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9423\n",
      "Epoch 66/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9423\n",
      "Epoch 67/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9231\n",
      "Epoch 68/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9423\n",
      "Epoch 69/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9231\n",
      "Epoch 70/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9423\n",
      "Epoch 71/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9231\n",
      "Epoch 72/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9423\n",
      "Epoch 73/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9423\n",
      "Epoch 74/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9231\n",
      "Epoch 75/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9423\n",
      "Epoch 76/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9423\n",
      "Epoch 77/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9423\n",
      "Epoch 78/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9423\n",
      "Epoch 79/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9423\n",
      "Epoch 80/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9423\n",
      "Epoch 81/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9423\n",
      "Epoch 82/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9423\n",
      "Epoch 83/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9423\n",
      "Epoch 84/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9231\n",
      "Epoch 85/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9423\n",
      "Epoch 86/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9423\n",
      "Epoch 87/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9423\n",
      "Epoch 88/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9423\n",
      "Epoch 89/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9231\n",
      "Epoch 90/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9423\n",
      "Epoch 91/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9423\n",
      "Epoch 92/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.4499e-04 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9423\n",
      "Epoch 93/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9231\n",
      "Epoch 94/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9423\n",
      "Epoch 95/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.2677e-04 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9423\n",
      "Epoch 96/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9423\n",
      "Epoch 97/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9423\n",
      "Epoch 98/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.3885e-04 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.9423\n",
      "Epoch 99/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.7778e-04 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9423\n",
      "Epoch 100/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.6604e-04 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9423\n",
      "Epoch 101/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9423\n",
      "Epoch 102/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.5493e-04 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 0.9231\n",
      "Epoch 103/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.7918e-04 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9423\n",
      "Epoch 104/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.4979e-04 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9231\n",
      "Epoch 105/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.6398e-04 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9423\n",
      "Epoch 106/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.3135e-04 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9423\n",
      "Epoch 107/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.3676e-04 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9423\n",
      "Epoch 108/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.4269e-04 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9423\n",
      "Epoch 109/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.1036e-04 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9423\n",
      "Epoch 110/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.9535e-04 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9423\n",
      "Epoch 111/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.7419e-04 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.9231\n",
      "Epoch 112/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.9567e-04 - accuracy: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.9231\n",
      "Epoch 113/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.7161e-04 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9423\n",
      "Epoch 114/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6077e-04 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9423\n",
      "Epoch 115/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.0440e-04 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9423\n",
      "Epoch 116/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4489e-04 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9423\n",
      "Epoch 117/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.7377e-04 - accuracy: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.9423\n",
      "Epoch 118/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.7080e-04 - accuracy: 1.0000 - val_loss: 0.3132 - val_accuracy: 0.9423\n",
      "Epoch 119/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.3857e-04 - accuracy: 1.0000 - val_loss: 0.3101 - val_accuracy: 0.9423\n",
      "Epoch 120/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.0457e-04 - accuracy: 1.0000 - val_loss: 0.3132 - val_accuracy: 0.9423\n",
      "Epoch 121/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.0284e-04 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9423\n",
      "Epoch 122/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.1357e-04 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9423\n",
      "Epoch 123/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.5861e-04 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 0.9423\n",
      "Epoch 124/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.1834e-04 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.9423\n",
      "Epoch 125/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.4731e-04 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.9423\n",
      "Epoch 126/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.0643e-04 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9423\n",
      "Epoch 127/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.8543e-04 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9423\n",
      "Epoch 128/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.6762e-04 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9423\n",
      "Epoch 129/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.0636e-04 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9231\n",
      "Epoch 130/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.3294e-04 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.9423\n",
      "Epoch 131/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3042e-04 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9423\n",
      "Epoch 132/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.5930e-04 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9423\n",
      "Epoch 133/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.6690e-04 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.9423\n",
      "Epoch 134/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.4218e-04 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 0.9423\n",
      "Epoch 135/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.3505e-04 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.9423\n",
      "Epoch 136/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.3457e-04 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 0.9423\n",
      "Epoch 137/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.3089e-04 - accuracy: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.9423\n",
      "Epoch 138/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.1355e-04 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9423\n",
      "Epoch 139/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.8390e-04 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9423\n",
      "Epoch 140/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.9832e-04 - accuracy: 1.0000 - val_loss: 0.3383 - val_accuracy: 0.9423\n",
      "Epoch 141/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.4781e-04 - accuracy: 1.0000 - val_loss: 0.3513 - val_accuracy: 0.9423\n",
      "Epoch 142/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.0884e-04 - accuracy: 1.0000 - val_loss: 0.3168 - val_accuracy: 0.9423\n",
      "Epoch 143/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.8285e-04 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.9423\n",
      "Epoch 144/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.1696e-04 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9423\n",
      "Epoch 145/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.8336e-04 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9423\n",
      "Epoch 146/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.7759e-04 - accuracy: 1.0000 - val_loss: 0.3210 - val_accuracy: 0.9423\n",
      "Epoch 147/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.7503e-04 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9423\n",
      "Epoch 148/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.9737e-04 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.9423\n",
      "Epoch 149/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.8611e-04 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9423\n",
      "Epoch 150/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.5951e-04 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.9423\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000191BBD09820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/150\n",
      "42/42 [==============================] - 1s 7ms/step - loss: 0.9233 - accuracy: 0.5362 - val_loss: 0.7039 - val_accuracy: 0.6154\n",
      "Epoch 2/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8406 - val_loss: 0.3261 - val_accuracy: 0.9038\n",
      "Epoch 3/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2066 - accuracy: 0.9420 - val_loss: 0.2378 - val_accuracy: 0.9038\n",
      "Epoch 4/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9565 - val_loss: 0.3641 - val_accuracy: 0.9038\n",
      "Epoch 5/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9614 - val_loss: 0.2083 - val_accuracy: 0.9231\n",
      "Epoch 6/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9903 - val_loss: 0.2873 - val_accuracy: 0.9038\n",
      "Epoch 7/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0744 - accuracy: 0.9710 - val_loss: 0.2985 - val_accuracy: 0.9038\n",
      "Epoch 8/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9807 - val_loss: 0.2497 - val_accuracy: 0.9038\n",
      "Epoch 9/150\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0331 - accuracy: 0.9952 - val_loss: 0.2738 - val_accuracy: 0.9038\n",
      "Epoch 10/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9807 - val_loss: 0.2851 - val_accuracy: 0.8846\n",
      "Epoch 11/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9855 - val_loss: 0.3574 - val_accuracy: 0.9038\n",
      "Epoch 12/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9038\n",
      "Epoch 13/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9952 - val_loss: 0.3168 - val_accuracy: 0.9038\n",
      "Epoch 14/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9038\n",
      "Epoch 15/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.3920 - val_accuracy: 0.9038\n",
      "Epoch 16/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9807 - val_loss: 0.3547 - val_accuracy: 0.9038\n",
      "Epoch 17/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9903 - val_loss: 0.3909 - val_accuracy: 0.9038\n",
      "Epoch 18/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9903 - val_loss: 0.3904 - val_accuracy: 0.9231\n",
      "Epoch 19/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.9038\n",
      "Epoch 20/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.9231\n",
      "Epoch 21/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.8846\n",
      "Epoch 22/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4196 - val_accuracy: 0.9231\n",
      "Epoch 23/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.9038\n",
      "Epoch 24/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9038\n",
      "Epoch 25/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.9038\n",
      "Epoch 26/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.9231\n",
      "Epoch 27/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.9038\n",
      "Epoch 28/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5412 - val_accuracy: 0.8846\n",
      "Epoch 29/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.9038\n",
      "Epoch 30/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.9038\n",
      "Epoch 31/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.9038\n",
      "Epoch 32/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.9231\n",
      "Epoch 33/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5381 - val_accuracy: 0.9038\n",
      "Epoch 34/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5342 - val_accuracy: 0.9038\n",
      "Epoch 35/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5564 - val_accuracy: 0.9038\n",
      "Epoch 36/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5193 - val_accuracy: 0.9231\n",
      "Epoch 37/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5788 - val_accuracy: 0.9038\n",
      "Epoch 38/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5838 - val_accuracy: 0.9038\n",
      "Epoch 39/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5767 - val_accuracy: 0.9038\n",
      "Epoch 40/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5770 - val_accuracy: 0.9038\n",
      "Epoch 41/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5641 - val_accuracy: 0.9038\n",
      "Epoch 42/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5981 - val_accuracy: 0.9038\n",
      "Epoch 43/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5917 - val_accuracy: 0.9038\n",
      "Epoch 44/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6005 - val_accuracy: 0.9038\n",
      "Epoch 45/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6016 - val_accuracy: 0.9038\n",
      "Epoch 46/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6083 - val_accuracy: 0.9038\n",
      "Epoch 47/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6383 - val_accuracy: 0.9038\n",
      "Epoch 48/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6209 - val_accuracy: 0.9038\n",
      "Epoch 49/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.9231\n",
      "Epoch 50/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5880 - val_accuracy: 0.9038\n",
      "Epoch 51/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6279 - val_accuracy: 0.9038\n",
      "Epoch 52/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.8324e-04 - accuracy: 1.0000 - val_loss: 0.6229 - val_accuracy: 0.9038\n",
      "Epoch 53/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6579 - val_accuracy: 0.9038\n",
      "Epoch 54/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.8338e-04 - accuracy: 1.0000 - val_loss: 0.6373 - val_accuracy: 0.9038\n",
      "Epoch 55/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.2400e-04 - accuracy: 1.0000 - val_loss: 0.6584 - val_accuracy: 0.9038\n",
      "Epoch 56/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.0252e-04 - accuracy: 1.0000 - val_loss: 0.6411 - val_accuracy: 0.9038\n",
      "Epoch 57/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.8356e-04 - accuracy: 1.0000 - val_loss: 0.6706 - val_accuracy: 0.9038\n",
      "Epoch 58/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.9324e-04 - accuracy: 1.0000 - val_loss: 0.6687 - val_accuracy: 0.9038\n",
      "Epoch 59/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.5789e-04 - accuracy: 1.0000 - val_loss: 0.6708 - val_accuracy: 0.9038\n",
      "Epoch 60/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.9602e-04 - accuracy: 1.0000 - val_loss: 0.6577 - val_accuracy: 0.9231\n",
      "Epoch 61/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.3782e-04 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.9038\n",
      "Epoch 62/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.6004e-04 - accuracy: 1.0000 - val_loss: 0.6829 - val_accuracy: 0.9038\n",
      "Epoch 63/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.3556e-04 - accuracy: 1.0000 - val_loss: 0.6662 - val_accuracy: 0.9231\n",
      "Epoch 64/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.2890e-04 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.9038\n",
      "Epoch 65/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.0077e-04 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.9038\n",
      "Epoch 66/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.8956e-04 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.9038\n",
      "Epoch 67/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.9061e-04 - accuracy: 1.0000 - val_loss: 0.7421 - val_accuracy: 0.9038\n",
      "Epoch 68/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.2385e-04 - accuracy: 1.0000 - val_loss: 0.7148 - val_accuracy: 0.9038\n",
      "Epoch 69/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3690e-04 - accuracy: 1.0000 - val_loss: 0.7129 - val_accuracy: 0.9038\n",
      "Epoch 70/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.3671e-04 - accuracy: 1.0000 - val_loss: 0.7419 - val_accuracy: 0.9038\n",
      "Epoch 71/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4679e-04 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.9038\n",
      "Epoch 72/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.7952e-04 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.9038\n",
      "Epoch 73/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.6196e-04 - accuracy: 1.0000 - val_loss: 0.7348 - val_accuracy: 0.9038\n",
      "Epoch 74/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.9653e-04 - accuracy: 1.0000 - val_loss: 0.7305 - val_accuracy: 0.9038\n",
      "Epoch 75/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.0417e-04 - accuracy: 1.0000 - val_loss: 0.7242 - val_accuracy: 0.9038\n",
      "Epoch 76/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.5949e-04 - accuracy: 1.0000 - val_loss: 0.7465 - val_accuracy: 0.9038\n",
      "Epoch 77/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.3570e-04 - accuracy: 1.0000 - val_loss: 0.7712 - val_accuracy: 0.9038\n",
      "Epoch 78/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.3686e-04 - accuracy: 1.0000 - val_loss: 0.7539 - val_accuracy: 0.9038\n",
      "Epoch 79/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.9608e-04 - accuracy: 1.0000 - val_loss: 0.7388 - val_accuracy: 0.9038\n",
      "Epoch 80/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.8786e-04 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.9038\n",
      "Epoch 81/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.8809e-04 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.9038\n",
      "Epoch 82/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.8240e-04 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.9038\n",
      "Epoch 83/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.7495e-04 - accuracy: 1.0000 - val_loss: 0.7507 - val_accuracy: 0.9038\n",
      "Epoch 84/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.4789e-04 - accuracy: 1.0000 - val_loss: 0.7660 - val_accuracy: 0.9038\n",
      "Epoch 85/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.3093e-04 - accuracy: 1.0000 - val_loss: 0.7810 - val_accuracy: 0.9038\n",
      "Epoch 86/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.2357e-04 - accuracy: 1.0000 - val_loss: 0.7743 - val_accuracy: 0.9038\n",
      "Epoch 87/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 2.2328e-04 - accuracy: 1.0000 - val_loss: 0.7743 - val_accuracy: 0.9038\n",
      "Epoch 88/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.2363e-04 - accuracy: 1.0000 - val_loss: 0.7838 - val_accuracy: 0.9038\n",
      "Epoch 89/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.0526e-04 - accuracy: 1.0000 - val_loss: 0.7876 - val_accuracy: 0.9038\n",
      "Epoch 90/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.9966e-04 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.9038\n",
      "Epoch 91/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.0410e-04 - accuracy: 1.0000 - val_loss: 0.8006 - val_accuracy: 0.9038\n",
      "Epoch 92/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.9331e-04 - accuracy: 1.0000 - val_loss: 0.7913 - val_accuracy: 0.9038\n",
      "Epoch 93/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.8015e-04 - accuracy: 1.0000 - val_loss: 0.8064 - val_accuracy: 0.9038\n",
      "Epoch 94/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.9611e-04 - accuracy: 1.0000 - val_loss: 0.7858 - val_accuracy: 0.9231\n",
      "Epoch 95/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.6638e-04 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.9038\n",
      "Epoch 96/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.8399e-04 - accuracy: 1.0000 - val_loss: 0.7976 - val_accuracy: 0.9038\n",
      "Epoch 97/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.5778e-04 - accuracy: 1.0000 - val_loss: 0.8084 - val_accuracy: 0.9038\n",
      "Epoch 98/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.5547e-04 - accuracy: 1.0000 - val_loss: 0.8174 - val_accuracy: 0.9038\n",
      "Epoch 99/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.6949e-04 - accuracy: 1.0000 - val_loss: 0.8161 - val_accuracy: 0.9038\n",
      "Epoch 100/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.5291e-04 - accuracy: 1.0000 - val_loss: 0.8177 - val_accuracy: 0.9038\n",
      "Epoch 101/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.4302e-04 - accuracy: 1.0000 - val_loss: 0.8347 - val_accuracy: 0.9038\n",
      "Epoch 102/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.5184e-04 - accuracy: 1.0000 - val_loss: 0.8270 - val_accuracy: 0.9038\n",
      "Epoch 103/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.3691e-04 - accuracy: 1.0000 - val_loss: 0.8344 - val_accuracy: 0.9038\n",
      "Epoch 104/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.2734e-04 - accuracy: 1.0000 - val_loss: 0.8323 - val_accuracy: 0.9038\n",
      "Epoch 105/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.2289e-04 - accuracy: 1.0000 - val_loss: 0.8433 - val_accuracy: 0.9038\n",
      "Epoch 106/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.2396e-04 - accuracy: 1.0000 - val_loss: 0.8421 - val_accuracy: 0.9038\n",
      "Epoch 107/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.2494e-04 - accuracy: 1.0000 - val_loss: 0.8542 - val_accuracy: 0.9038\n",
      "Epoch 108/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.1608e-04 - accuracy: 1.0000 - val_loss: 0.8451 - val_accuracy: 0.9038\n",
      "Epoch 109/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.1159e-04 - accuracy: 1.0000 - val_loss: 0.8431 - val_accuracy: 0.9038\n",
      "Epoch 110/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.0696e-04 - accuracy: 1.0000 - val_loss: 0.8549 - val_accuracy: 0.9038\n",
      "Epoch 111/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.0797e-04 - accuracy: 1.0000 - val_loss: 0.8427 - val_accuracy: 0.9231\n",
      "Epoch 112/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.0717e-04 - accuracy: 1.0000 - val_loss: 0.8591 - val_accuracy: 0.9038\n",
      "Epoch 113/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.8406e-05 - accuracy: 1.0000 - val_loss: 0.8743 - val_accuracy: 0.9038\n",
      "Epoch 114/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.9143e-05 - accuracy: 1.0000 - val_loss: 0.8611 - val_accuracy: 0.9038\n",
      "Epoch 115/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.0437e-04 - accuracy: 1.0000 - val_loss: 0.8557 - val_accuracy: 0.9231\n",
      "Epoch 116/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.2799e-05 - accuracy: 1.0000 - val_loss: 0.8667 - val_accuracy: 0.9038\n",
      "Epoch 117/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.7744e-05 - accuracy: 1.0000 - val_loss: 0.8724 - val_accuracy: 0.9038\n",
      "Epoch 118/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.6300e-05 - accuracy: 1.0000 - val_loss: 0.8644 - val_accuracy: 0.9231\n",
      "Epoch 119/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.4932e-05 - accuracy: 1.0000 - val_loss: 0.8798 - val_accuracy: 0.9038\n",
      "Epoch 120/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 8.2232e-05 - accuracy: 1.0000 - val_loss: 0.8796 - val_accuracy: 0.9038\n",
      "Epoch 121/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.7073e-05 - accuracy: 1.0000 - val_loss: 0.8972 - val_accuracy: 0.9038\n",
      "Epoch 122/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.6958e-05 - accuracy: 1.0000 - val_loss: 0.8898 - val_accuracy: 0.9038\n",
      "Epoch 123/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.5478e-05 - accuracy: 1.0000 - val_loss: 0.8957 - val_accuracy: 0.9038\n",
      "Epoch 124/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.8192e-05 - accuracy: 1.0000 - val_loss: 0.8872 - val_accuracy: 0.9038\n",
      "Epoch 125/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 7.6295e-05 - accuracy: 1.0000 - val_loss: 0.8970 - val_accuracy: 0.9038\n",
      "Epoch 126/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.6280e-05 - accuracy: 1.0000 - val_loss: 0.9151 - val_accuracy: 0.9038\n",
      "Epoch 127/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.5757e-05 - accuracy: 1.0000 - val_loss: 0.9044 - val_accuracy: 0.9038\n",
      "Epoch 128/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.4797e-05 - accuracy: 1.0000 - val_loss: 0.9154 - val_accuracy: 0.9038\n",
      "Epoch 129/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.2011e-05 - accuracy: 1.0000 - val_loss: 0.9185 - val_accuracy: 0.9038\n",
      "Epoch 130/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 5.9592e-05 - accuracy: 1.0000 - val_loss: 0.9169 - val_accuracy: 0.9038\n",
      "Epoch 131/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.6605e-05 - accuracy: 1.0000 - val_loss: 0.9239 - val_accuracy: 0.9038\n",
      "Epoch 132/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 6.1341e-05 - accuracy: 1.0000 - val_loss: 0.9199 - val_accuracy: 0.9038\n",
      "Epoch 133/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.8710e-05 - accuracy: 1.0000 - val_loss: 0.9157 - val_accuracy: 0.9038\n",
      "Epoch 134/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.4159e-05 - accuracy: 1.0000 - val_loss: 0.9279 - val_accuracy: 0.9038\n",
      "Epoch 135/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.3521e-05 - accuracy: 1.0000 - val_loss: 0.9283 - val_accuracy: 0.9038\n",
      "Epoch 136/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.1052e-05 - accuracy: 1.0000 - val_loss: 0.9482 - val_accuracy: 0.9038\n",
      "Epoch 137/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.0105e-05 - accuracy: 1.0000 - val_loss: 0.9268 - val_accuracy: 0.9231\n",
      "Epoch 138/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.0311e-05 - accuracy: 1.0000 - val_loss: 0.9344 - val_accuracy: 0.9038\n",
      "Epoch 139/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6466e-05 - accuracy: 1.0000 - val_loss: 0.9406 - val_accuracy: 0.9038\n",
      "Epoch 140/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.5810e-05 - accuracy: 1.0000 - val_loss: 0.9529 - val_accuracy: 0.9038\n",
      "Epoch 141/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.1241e-05 - accuracy: 1.0000 - val_loss: 0.9656 - val_accuracy: 0.9038\n",
      "Epoch 142/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.4390e-05 - accuracy: 1.0000 - val_loss: 0.9472 - val_accuracy: 0.9038\n",
      "Epoch 143/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 4.2061e-05 - accuracy: 1.0000 - val_loss: 0.9549 - val_accuracy: 0.9038\n",
      "Epoch 144/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.1412e-05 - accuracy: 1.0000 - val_loss: 0.9501 - val_accuracy: 0.9038\n",
      "Epoch 145/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.9083e-05 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9038\n",
      "Epoch 146/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.8794e-05 - accuracy: 1.0000 - val_loss: 0.9595 - val_accuracy: 0.9038\n",
      "Epoch 147/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.7049e-05 - accuracy: 1.0000 - val_loss: 0.9738 - val_accuracy: 0.9038\n",
      "Epoch 148/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.6568e-05 - accuracy: 1.0000 - val_loss: 0.9699 - val_accuracy: 0.9038\n",
      "Epoch 149/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.8991e-05 - accuracy: 1.0000 - val_loss: 0.9735 - val_accuracy: 0.9038\n",
      "Epoch 150/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.5306e-05 - accuracy: 1.0000 - val_loss: 0.9752 - val_accuracy: 0.9038\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000191B8C57550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/150\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.9359 - accuracy: 0.6490 - val_loss: 0.6864 - val_accuracy: 0.7451\n",
      "Epoch 2/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.7644 - val_loss: 0.5751 - val_accuracy: 0.7451\n",
      "Epoch 3/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7788 - val_loss: 0.3975 - val_accuracy: 0.8431\n",
      "Epoch 4/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.9231 - val_loss: 0.2034 - val_accuracy: 0.9804\n",
      "Epoch 5/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.9423 - val_loss: 0.1218 - val_accuracy: 0.9804\n",
      "Epoch 6/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.9279 - val_loss: 0.1558 - val_accuracy: 0.9216\n",
      "Epoch 7/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.9808 - val_loss: 0.2139 - val_accuracy: 0.8824\n",
      "Epoch 8/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9327 - val_loss: 0.0901 - val_accuracy: 0.9608\n",
      "Epoch 9/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1161 - accuracy: 0.9471 - val_loss: 0.0844 - val_accuracy: 1.0000\n",
      "Epoch 10/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9615 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
      "Epoch 11/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9663 - val_loss: 0.0641 - val_accuracy: 1.0000\n",
      "Epoch 12/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.9712 - val_loss: 0.0992 - val_accuracy: 0.9608\n",
      "Epoch 13/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0799 - accuracy: 0.9615 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
      "Epoch 14/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9808 - val_loss: 0.0805 - val_accuracy: 0.9804\n",
      "Epoch 15/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9760 - val_loss: 0.0671 - val_accuracy: 0.9804\n",
      "Epoch 16/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9615 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
      "Epoch 17/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.9615 - val_loss: 0.0864 - val_accuracy: 0.9412\n",
      "Epoch 18/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.9663 - val_loss: 0.1587 - val_accuracy: 0.9020\n",
      "Epoch 19/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9712 - val_loss: 0.0836 - val_accuracy: 0.9216\n",
      "Epoch 20/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9712 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.9904 - val_loss: 0.0367 - val_accuracy: 0.9804\n",
      "Epoch 22/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9712 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9760 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9904 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9760 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9856 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9952 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9904 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9952 - val_loss: 0.0491 - val_accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9904 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9904 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9952 - val_loss: 0.0530 - val_accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9952 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9412\n",
      "Epoch 35/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9952 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9952 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9904 - val_loss: 0.0803 - val_accuracy: 0.9608\n",
      "Epoch 38/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9904 - val_loss: 0.0628 - val_accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9952 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9952 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9904 - val_loss: 0.0545 - val_accuracy: 0.9804\n",
      "Epoch 42/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9904 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9804\n",
      "Epoch 44/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9904 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9904 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9804\n",
      "Epoch 47/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9608\n",
      "Epoch 49/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9804\n",
      "Epoch 51/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9608\n",
      "Epoch 52/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9804\n",
      "Epoch 54/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9804\n",
      "Epoch 56/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9804\n",
      "Epoch 67/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9804\n",
      "Epoch 69/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9804\n",
      "Epoch 78/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9216\n",
      "Epoch 96/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1284 - accuracy: 0.9567 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9663 - val_loss: 0.4344 - val_accuracy: 0.8824\n",
      "Epoch 98/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9856 - val_loss: 0.0435 - val_accuracy: 0.9804\n",
      "Epoch 99/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9804\n",
      "Epoch 101/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9412\n",
      "Epoch 102/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9952 - val_loss: 0.0265 - val_accuracy: 0.9804\n",
      "Epoch 103/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9904 - val_loss: 0.0952 - val_accuracy: 0.9608\n",
      "Epoch 104/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9663 - val_loss: 0.0390 - val_accuracy: 0.9804\n",
      "Epoch 105/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9608\n",
      "Epoch 106/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9804\n",
      "Epoch 109/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 0.9608\n",
      "Epoch 116/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9804\n",
      "Epoch 129/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9804\n",
      "Epoch 136/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9804\n",
      "Epoch 137/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9804\n",
      "Epoch 141/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9804\n",
      "Epoch 146/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.2974e-04 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.2098e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.7743e-04 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.2726e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.8787e-04 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9804\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        64\n",
      "           1       1.00      1.00      1.00        65\n",
      "           2       0.87      0.92      0.90        65\n",
      "           3       0.92      0.86      0.89        65\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.95      0.95      0.95       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"C:/Users/franu/Downloads/RedesNeuronales/Actividad1/misterious_data_4.txt\") \n",
    "x = data[:,1:]\n",
    "y = data[:,0]\n",
    "\n",
    "# Convert target labels to start from 0\n",
    "y = y.astype(int) - 1\n",
    "\n",
    "#targets = data.target_names\n",
    "n_clases = len(np.unique(y))\n",
    "\n",
    "#features = data.feature_names\n",
    "n_features = x.shape[1]\n",
    "\n",
    "# Create output variables from original labels. This is required only in multiclass problems.\n",
    "output_y = np_utils.to_categorical(y)   \n",
    "print(output_y)\n",
    "\n",
    "# Define MLP model\n",
    "clf = Sequential()\n",
    "clf.add(Dense(10, input_dim=n_features, activation='relu'))\n",
    "clf.add(Dense(10, activation='relu'))\n",
    "clf.add(Dense(4, activation='softmax')) # for 2-class problems, use clf.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " \n",
    "# Fit model\n",
    "clf.fit(x, output_y, epochs=150, batch_size=5)\n",
    "\n",
    "# Evaluate model\n",
    "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "\n",
    "cv_y_test = []\n",
    "cv_y_pred = []\n",
    "\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "\n",
    "    x_train = x[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "    y_train_categorical = np_utils.to_categorical(y_train)\n",
    "\n",
    "    x_test = x[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "    y_test_categorical = np_utils.to_categorical(y_test)\n",
    "\n",
    "    # Training phase\n",
    "    clf_cv = Sequential()\n",
    "    clf_cv.add(Dense(10, input_dim=n_features, activation='relu'))\n",
    "    clf_cv.add(Dense(10, activation='relu'))\n",
    "    clf_cv.add(Dense(4, activation='softmax'))\n",
    "    clf_cv.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    clf_cv.fit(x_train, y_train_categorical, validation_data= (x_test, y_test_categorical), epochs=150, batch_size=5)    \n",
    "\n",
    "    # Test phase\n",
    "    x_test = x[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "    y_pred = np.argmax(clf_cv.predict(x_test), axis=-1)  \n",
    "\n",
    "    cv_y_test.append(y_test)\n",
    "    cv_y_pred.append(y_pred)\n",
    "\n",
    "\n",
    "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Para el conjunto de datos diabetes, ajusta un modelo de regresión perceptrón multicapa, y evalúa el error cuadrático medio del modelo con validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 1s 3ms/step - loss: 29680.4824\n",
      "Epoch 2/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 29401.9863\n",
      "Epoch 3/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 28639.2461\n",
      "Epoch 4/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 27084.5801\n",
      "Epoch 5/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 24547.4609\n",
      "Epoch 6/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 21112.8848\n",
      "Epoch 7/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 17138.0645\n",
      "Epoch 8/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 13137.2227\n",
      "Epoch 9/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 9769.5537\n",
      "Epoch 10/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 7309.7896\n",
      "Epoch 11/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 5840.5083\n",
      "Epoch 12/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 5081.1821\n",
      "Epoch 13/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4717.1484\n",
      "Epoch 14/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4540.4297\n",
      "Epoch 15/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4412.2671\n",
      "Epoch 16/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4298.5791\n",
      "Epoch 17/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4202.3643\n",
      "Epoch 18/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4111.8550\n",
      "Epoch 19/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4032.9971\n",
      "Epoch 20/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3957.3577\n",
      "Epoch 21/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3888.4150\n",
      "Epoch 22/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3823.9500\n",
      "Epoch 23/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3761.0449\n",
      "Epoch 24/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3695.4424\n",
      "Epoch 25/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3645.4041\n",
      "Epoch 26/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3587.7776\n",
      "Epoch 27/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3540.4822\n",
      "Epoch 28/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3496.8167\n",
      "Epoch 29/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3448.8340\n",
      "Epoch 30/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3413.5996\n",
      "Epoch 31/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3378.9136\n",
      "Epoch 32/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3346.7993\n",
      "Epoch 33/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3315.8540\n",
      "Epoch 34/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3291.0493\n",
      "Epoch 35/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3261.6138\n",
      "Epoch 36/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3235.6304\n",
      "Epoch 37/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3219.4487\n",
      "Epoch 38/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3196.9424\n",
      "Epoch 39/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3180.4456\n",
      "Epoch 40/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3159.4165\n",
      "Epoch 41/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3140.6604\n",
      "Epoch 42/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3134.3599\n",
      "Epoch 43/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3121.9685\n",
      "Epoch 44/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3099.8774\n",
      "Epoch 45/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3081.1279\n",
      "Epoch 46/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3070.1072\n",
      "Epoch 47/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3061.9500\n",
      "Epoch 48/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3044.8650\n",
      "Epoch 49/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3034.9158\n",
      "Epoch 50/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3032.9500\n",
      "Epoch 51/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3017.0276\n",
      "Epoch 52/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3009.3396\n",
      "Epoch 53/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3005.4058\n",
      "Epoch 54/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2996.8914\n",
      "Epoch 55/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2983.3477\n",
      "Epoch 56/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2980.5977\n",
      "Epoch 57/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2969.7676\n",
      "Epoch 58/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2964.4980\n",
      "Epoch 59/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2959.2544\n",
      "Epoch 60/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2950.0454\n",
      "Epoch 61/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2946.3862\n",
      "Epoch 62/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2942.9722\n",
      "Epoch 63/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2939.3625\n",
      "Epoch 64/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2937.6221\n",
      "Epoch 65/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2936.9983\n",
      "Epoch 66/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2929.4670\n",
      "Epoch 67/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2922.9373\n",
      "Epoch 68/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2929.7695\n",
      "Epoch 69/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2920.3914\n",
      "Epoch 70/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2919.5918\n",
      "Epoch 71/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2910.2090\n",
      "Epoch 72/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2914.4304\n",
      "Epoch 73/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2907.0613\n",
      "Epoch 74/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2906.8953\n",
      "Epoch 75/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2909.0713\n",
      "Epoch 76/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2907.2705\n",
      "Epoch 77/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2903.7583\n",
      "Epoch 78/150\n",
      "71/71 [==============================] - 0s 930us/step - loss: 2899.0125\n",
      "Epoch 79/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2897.3135\n",
      "Epoch 80/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2892.0032\n",
      "Epoch 81/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2900.1865\n",
      "Epoch 82/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2896.9546\n",
      "Epoch 83/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2899.1218\n",
      "Epoch 84/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2891.7332\n",
      "Epoch 85/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2895.3811\n",
      "Epoch 86/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2890.9978\n",
      "Epoch 87/150\n",
      "71/71 [==============================] - 0s 938us/step - loss: 2889.0476\n",
      "Epoch 88/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2892.6833\n",
      "Epoch 89/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2889.6882\n",
      "Epoch 90/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2887.0378\n",
      "Epoch 91/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2894.8018\n",
      "Epoch 92/150\n",
      "71/71 [==============================] - 0s 915us/step - loss: 2886.4573\n",
      "Epoch 93/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2882.6221\n",
      "Epoch 94/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2881.1030\n",
      "Epoch 95/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2880.2258\n",
      "Epoch 96/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2879.7974\n",
      "Epoch 97/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2888.8477\n",
      "Epoch 98/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2880.9795\n",
      "Epoch 99/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2882.4707\n",
      "Epoch 100/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2886.1897\n",
      "Epoch 101/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2879.9780\n",
      "Epoch 102/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2877.9121\n",
      "Epoch 103/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2876.5542\n",
      "Epoch 104/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2877.4431\n",
      "Epoch 105/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2880.3928\n",
      "Epoch 106/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2881.7395\n",
      "Epoch 107/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2881.9456\n",
      "Epoch 108/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2876.3706\n",
      "Epoch 109/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2887.2820\n",
      "Epoch 110/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2878.1318\n",
      "Epoch 111/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2874.8945\n",
      "Epoch 112/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2874.8140\n",
      "Epoch 113/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2874.9326\n",
      "Epoch 114/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2875.0757\n",
      "Epoch 115/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2878.2334\n",
      "Epoch 116/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2874.8081\n",
      "Epoch 117/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2873.0667\n",
      "Epoch 118/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2877.0120\n",
      "Epoch 119/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2878.0100\n",
      "Epoch 120/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2882.2793\n",
      "Epoch 121/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2873.4197\n",
      "Epoch 122/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2873.2876\n",
      "Epoch 123/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2873.2463\n",
      "Epoch 124/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2877.5544\n",
      "Epoch 125/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2872.1704\n",
      "Epoch 126/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2870.7363\n",
      "Epoch 127/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2880.0293\n",
      "Epoch 128/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2871.1670\n",
      "Epoch 129/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2871.0833\n",
      "Epoch 130/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2876.9866\n",
      "Epoch 131/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2873.9272\n",
      "Epoch 132/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2870.3689\n",
      "Epoch 133/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2871.6846\n",
      "Epoch 134/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2871.2146\n",
      "Epoch 135/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2874.0000\n",
      "Epoch 136/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2869.6072\n",
      "Epoch 137/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2870.5647\n",
      "Epoch 138/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2867.4099\n",
      "Epoch 139/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2872.2490\n",
      "Epoch 140/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2877.6987\n",
      "Epoch 141/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2864.7698\n",
      "Epoch 142/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2872.8071\n",
      "Epoch 143/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2875.8169\n",
      "Epoch 144/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2877.0010\n",
      "Epoch 145/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2871.1108\n",
      "Epoch 146/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2870.6780\n",
      "Epoch 147/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2873.5808\n",
      "Epoch 148/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2866.9194\n",
      "Epoch 149/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2870.2954\n",
      "Epoch 150/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2871.8232\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "Epoch 1/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3056.6375\n",
      "Epoch 2/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3049.5608\n",
      "Epoch 3/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3050.7058\n",
      "Epoch 4/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3046.9529\n",
      "Epoch 5/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3046.0750\n",
      "Epoch 6/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3042.8296\n",
      "Epoch 7/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3046.6133\n",
      "Epoch 8/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3043.1990\n",
      "Epoch 9/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3040.8186\n",
      "Epoch 10/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3042.4392\n",
      "Epoch 11/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3040.4746\n",
      "Epoch 12/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3045.2195\n",
      "Epoch 13/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3040.0723\n",
      "Epoch 14/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3037.6038\n",
      "Epoch 15/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3035.5276\n",
      "Epoch 16/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3034.0132\n",
      "Epoch 17/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3033.5815\n",
      "Epoch 18/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3037.1218\n",
      "Epoch 19/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3028.5181\n",
      "Epoch 20/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3033.0676\n",
      "Epoch 21/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3040.6338\n",
      "Epoch 22/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3036.5095\n",
      "Epoch 23/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3035.4575\n",
      "Epoch 24/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3030.5686\n",
      "Epoch 25/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3027.7295\n",
      "Epoch 26/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3028.2366\n",
      "Epoch 27/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3032.9324\n",
      "Epoch 28/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3033.4424\n",
      "Epoch 29/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3038.3901\n",
      "Epoch 30/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3025.7930\n",
      "Epoch 31/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3025.8945\n",
      "Epoch 32/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3033.5435\n",
      "Epoch 33/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3024.5422\n",
      "Epoch 34/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3031.9075\n",
      "Epoch 35/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3029.2537\n",
      "Epoch 36/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3029.0454\n",
      "Epoch 37/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3025.6106\n",
      "Epoch 38/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3027.2012\n",
      "Epoch 39/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3026.2344\n",
      "Epoch 40/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3022.6428\n",
      "Epoch 41/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3022.4387\n",
      "Epoch 42/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3023.4746\n",
      "Epoch 43/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3035.2446\n",
      "Epoch 44/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3023.7227\n",
      "Epoch 45/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3022.7400\n",
      "Epoch 46/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3028.2776\n",
      "Epoch 47/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3021.6958\n",
      "Epoch 48/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3023.8743\n",
      "Epoch 49/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3022.9600\n",
      "Epoch 50/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3021.4214\n",
      "Epoch 51/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3021.1006\n",
      "Epoch 52/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3023.4238\n",
      "Epoch 53/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3016.0808\n",
      "Epoch 54/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3033.8311\n",
      "Epoch 55/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3023.9624\n",
      "Epoch 56/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3016.4836\n",
      "Epoch 57/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3023.5273\n",
      "Epoch 58/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3020.0298\n",
      "Epoch 59/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3018.4224\n",
      "Epoch 60/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3019.3425\n",
      "Epoch 61/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3017.8442\n",
      "Epoch 62/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3017.9041\n",
      "Epoch 63/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3016.8796\n",
      "Epoch 64/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3019.9043\n",
      "Epoch 65/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3019.1282\n",
      "Epoch 66/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3019.0120\n",
      "Epoch 67/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3026.2844\n",
      "Epoch 68/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3015.9106\n",
      "Epoch 69/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3020.2554\n",
      "Epoch 70/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3016.2986\n",
      "Epoch 71/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3019.3130\n",
      "Epoch 72/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3014.0828\n",
      "Epoch 73/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3017.6060\n",
      "Epoch 74/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3018.5022\n",
      "Epoch 75/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3017.0195\n",
      "Epoch 76/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3014.7805\n",
      "Epoch 77/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3021.9043\n",
      "Epoch 78/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3011.6704\n",
      "Epoch 79/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3012.8752\n",
      "Epoch 80/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3012.7437\n",
      "Epoch 81/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3014.8057\n",
      "Epoch 82/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3015.3860\n",
      "Epoch 83/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3017.1279\n",
      "Epoch 84/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3013.5251\n",
      "Epoch 85/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3014.1826\n",
      "Epoch 86/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3013.5518\n",
      "Epoch 87/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3017.4629\n",
      "Epoch 88/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3018.0591\n",
      "Epoch 89/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3011.5344\n",
      "Epoch 90/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3014.3608\n",
      "Epoch 91/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3011.9680\n",
      "Epoch 92/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3018.5266\n",
      "Epoch 93/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3013.6194\n",
      "Epoch 94/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3016.4490\n",
      "Epoch 95/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3010.0605\n",
      "Epoch 96/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3017.1877\n",
      "Epoch 97/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3013.8662\n",
      "Epoch 98/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3013.9255\n",
      "Epoch 99/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3022.2791\n",
      "Epoch 100/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3016.0378\n",
      "Epoch 101/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3010.6006\n",
      "Epoch 102/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3012.8643\n",
      "Epoch 103/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3010.0557\n",
      "Epoch 104/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3018.2437\n",
      "Epoch 105/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3011.8630\n",
      "Epoch 106/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3020.6079\n",
      "Epoch 107/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3014.8608\n",
      "Epoch 108/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3017.9543\n",
      "Epoch 109/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3012.7563\n",
      "Epoch 110/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3009.7698\n",
      "Epoch 111/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3015.1550\n",
      "Epoch 112/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3011.8677\n",
      "Epoch 113/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3024.8804\n",
      "Epoch 114/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3009.3516\n",
      "Epoch 115/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3008.5754\n",
      "Epoch 116/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3009.8411\n",
      "Epoch 117/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3013.8867\n",
      "Epoch 118/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3011.2981\n",
      "Epoch 119/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3010.0312\n",
      "Epoch 120/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3012.4133\n",
      "Epoch 121/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3009.3625\n",
      "Epoch 122/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3010.7734\n",
      "Epoch 123/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3012.3506\n",
      "Epoch 124/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3015.2170\n",
      "Epoch 125/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3016.8962\n",
      "Epoch 126/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3013.1038\n",
      "Epoch 127/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3012.3184\n",
      "Epoch 128/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3008.5149\n",
      "Epoch 129/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3010.6313\n",
      "Epoch 130/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3018.3120\n",
      "Epoch 131/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3007.7688\n",
      "Epoch 132/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3014.9404\n",
      "Epoch 133/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3013.0339\n",
      "Epoch 134/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3012.4468\n",
      "Epoch 135/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3009.0527\n",
      "Epoch 136/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3007.8013\n",
      "Epoch 137/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3011.0793\n",
      "Epoch 138/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3014.7649\n",
      "Epoch 139/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3009.1799\n",
      "Epoch 140/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3003.4822\n",
      "Epoch 141/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3013.9890\n",
      "Epoch 142/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3007.7852\n",
      "Epoch 143/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3010.0151\n",
      "Epoch 144/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3008.9275\n",
      "Epoch 145/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3008.7915\n",
      "Epoch 146/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3006.1150\n",
      "Epoch 147/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3013.1321\n",
      "Epoch 148/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3012.1194\n",
      "Epoch 149/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3008.1895\n",
      "Epoch 150/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3008.3020\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Epoch 1/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2791.4082\n",
      "Epoch 2/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2773.4824\n",
      "Epoch 3/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2772.3145\n",
      "Epoch 4/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2772.7043\n",
      "Epoch 5/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2771.4255\n",
      "Epoch 6/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2774.7310\n",
      "Epoch 7/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2772.5022\n",
      "Epoch 8/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2774.4333\n",
      "Epoch 9/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2775.5149\n",
      "Epoch 10/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2772.3899\n",
      "Epoch 11/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2771.1089\n",
      "Epoch 12/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2768.9275\n",
      "Epoch 13/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2765.4456\n",
      "Epoch 14/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2767.6587\n",
      "Epoch 15/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2769.7129\n",
      "Epoch 16/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2766.4146\n",
      "Epoch 17/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2764.9995\n",
      "Epoch 18/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2769.7415\n",
      "Epoch 19/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2771.6604\n",
      "Epoch 20/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2766.4846\n",
      "Epoch 21/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2775.4175\n",
      "Epoch 22/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2767.3188\n",
      "Epoch 23/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2766.0176\n",
      "Epoch 24/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2766.5437\n",
      "Epoch 25/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2766.9612\n",
      "Epoch 26/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2765.2666\n",
      "Epoch 27/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2763.6990\n",
      "Epoch 28/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2769.9639\n",
      "Epoch 29/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2763.0374\n",
      "Epoch 30/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2762.4919\n",
      "Epoch 31/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2766.1624\n",
      "Epoch 32/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2765.7878\n",
      "Epoch 33/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2768.2502\n",
      "Epoch 34/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2760.8083\n",
      "Epoch 35/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2762.0325\n",
      "Epoch 36/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2763.0720\n",
      "Epoch 37/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2764.2864\n",
      "Epoch 38/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2763.5859\n",
      "Epoch 39/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2763.6907\n",
      "Epoch 40/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2768.0408\n",
      "Epoch 41/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2767.4629\n",
      "Epoch 42/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2764.6216\n",
      "Epoch 43/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2771.7388\n",
      "Epoch 44/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2764.7930\n",
      "Epoch 45/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2764.4309\n",
      "Epoch 46/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2764.4980\n",
      "Epoch 47/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2758.5059\n",
      "Epoch 48/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2764.8501\n",
      "Epoch 49/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2763.1660\n",
      "Epoch 50/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2760.9099\n",
      "Epoch 51/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2762.2539\n",
      "Epoch 52/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2758.8931\n",
      "Epoch 53/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2759.8091\n",
      "Epoch 54/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2764.1663\n",
      "Epoch 55/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2758.5046\n",
      "Epoch 56/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2763.7231\n",
      "Epoch 57/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2763.1868\n",
      "Epoch 58/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2762.5183\n",
      "Epoch 59/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2762.4351\n",
      "Epoch 60/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2769.6909\n",
      "Epoch 61/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2767.3352\n",
      "Epoch 62/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2760.5381\n",
      "Epoch 63/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2760.9646\n",
      "Epoch 64/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2758.0281\n",
      "Epoch 65/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2765.2715\n",
      "Epoch 66/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2758.7969\n",
      "Epoch 67/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2759.2471\n",
      "Epoch 68/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2763.0767\n",
      "Epoch 69/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2758.1101\n",
      "Epoch 70/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2755.9946\n",
      "Epoch 71/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2757.6396\n",
      "Epoch 72/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2759.2871\n",
      "Epoch 73/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2763.2988\n",
      "Epoch 74/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2758.2417\n",
      "Epoch 75/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2757.4951\n",
      "Epoch 76/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2757.3271\n",
      "Epoch 77/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2759.0386\n",
      "Epoch 78/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2761.7649\n",
      "Epoch 79/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2767.2778\n",
      "Epoch 80/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2765.2332\n",
      "Epoch 81/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2761.2581\n",
      "Epoch 82/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2764.6460\n",
      "Epoch 83/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2757.1267\n",
      "Epoch 84/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2756.5530\n",
      "Epoch 85/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2759.0769\n",
      "Epoch 86/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2759.7871\n",
      "Epoch 87/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2759.6772\n",
      "Epoch 88/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2755.3982\n",
      "Epoch 89/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2761.2295\n",
      "Epoch 90/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2759.2305\n",
      "Epoch 91/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2760.3335\n",
      "Epoch 92/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2755.3391\n",
      "Epoch 93/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2759.4231\n",
      "Epoch 94/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2758.1814\n",
      "Epoch 95/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2755.6255\n",
      "Epoch 96/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2755.2761\n",
      "Epoch 97/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2762.0947\n",
      "Epoch 98/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2756.7585\n",
      "Epoch 99/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2757.1177\n",
      "Epoch 100/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2763.0669\n",
      "Epoch 101/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2758.3176\n",
      "Epoch 102/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2753.7095\n",
      "Epoch 103/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2755.2803\n",
      "Epoch 104/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2757.2229\n",
      "Epoch 105/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2757.3511\n",
      "Epoch 106/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2757.2034\n",
      "Epoch 107/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2754.8950\n",
      "Epoch 108/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2753.3621\n",
      "Epoch 109/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2760.9048\n",
      "Epoch 110/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2757.3867\n",
      "Epoch 111/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2756.7478\n",
      "Epoch 112/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2758.1431\n",
      "Epoch 113/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2759.5750\n",
      "Epoch 114/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2753.7434\n",
      "Epoch 115/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2757.4614\n",
      "Epoch 116/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2757.6013\n",
      "Epoch 117/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2760.6719\n",
      "Epoch 118/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2761.1853\n",
      "Epoch 119/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2757.4900\n",
      "Epoch 120/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2757.7349\n",
      "Epoch 121/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2758.6643\n",
      "Epoch 122/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2753.7795\n",
      "Epoch 123/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2756.1125\n",
      "Epoch 124/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2760.7654\n",
      "Epoch 125/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2762.1440\n",
      "Epoch 126/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2761.4143\n",
      "Epoch 127/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2756.0342\n",
      "Epoch 128/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2755.4048\n",
      "Epoch 129/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2757.5461\n",
      "Epoch 130/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2759.0798\n",
      "Epoch 131/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2756.0437\n",
      "Epoch 132/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2760.3889\n",
      "Epoch 133/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2759.6379\n",
      "Epoch 134/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2757.9868\n",
      "Epoch 135/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2759.1101\n",
      "Epoch 136/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2760.3503\n",
      "Epoch 137/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2763.9944\n",
      "Epoch 138/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2756.5896\n",
      "Epoch 139/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2755.6147\n",
      "Epoch 140/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2753.2617\n",
      "Epoch 141/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2751.0242\n",
      "Epoch 142/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2759.2043\n",
      "Epoch 143/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2761.8848\n",
      "Epoch 144/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2754.7668\n",
      "Epoch 145/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2753.8186\n",
      "Epoch 146/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2761.0479\n",
      "Epoch 147/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2753.9456\n",
      "Epoch 148/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2753.0427\n",
      "Epoch 149/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2755.4905\n",
      "Epoch 150/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2752.8394\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "Epoch 1/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2745.7747\n",
      "Epoch 2/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2746.6882\n",
      "Epoch 3/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2745.2563\n",
      "Epoch 4/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2746.1980\n",
      "Epoch 5/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2742.3076\n",
      "Epoch 6/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2744.7859\n",
      "Epoch 7/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2736.3740\n",
      "Epoch 8/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2743.3418\n",
      "Epoch 9/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2739.3735\n",
      "Epoch 10/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2737.8088\n",
      "Epoch 11/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2734.7954\n",
      "Epoch 12/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2739.0000\n",
      "Epoch 13/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2734.1399\n",
      "Epoch 14/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2731.8420\n",
      "Epoch 15/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2729.8601\n",
      "Epoch 16/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2735.0237\n",
      "Epoch 17/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2729.9780\n",
      "Epoch 18/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2733.7827\n",
      "Epoch 19/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2729.4773\n",
      "Epoch 20/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2730.3066\n",
      "Epoch 21/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2727.0020\n",
      "Epoch 22/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2734.9736\n",
      "Epoch 23/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2726.7263\n",
      "Epoch 24/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2733.1853\n",
      "Epoch 25/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2727.7659\n",
      "Epoch 26/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2725.8328\n",
      "Epoch 27/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2728.7336\n",
      "Epoch 28/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2736.6309\n",
      "Epoch 29/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2726.8601\n",
      "Epoch 30/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2726.3125\n",
      "Epoch 31/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2721.2375\n",
      "Epoch 32/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2721.3965\n",
      "Epoch 33/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2720.5085\n",
      "Epoch 34/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2723.6375\n",
      "Epoch 35/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2721.5967\n",
      "Epoch 36/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2722.3083\n",
      "Epoch 37/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2724.6572\n",
      "Epoch 38/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2721.2329\n",
      "Epoch 39/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2726.3833\n",
      "Epoch 40/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2721.7378\n",
      "Epoch 41/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2725.4209\n",
      "Epoch 42/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2718.4258\n",
      "Epoch 43/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2721.1279\n",
      "Epoch 44/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2718.0754\n",
      "Epoch 45/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2720.2786\n",
      "Epoch 46/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2719.3186\n",
      "Epoch 47/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2720.4014\n",
      "Epoch 48/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2725.0764\n",
      "Epoch 49/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2716.4634\n",
      "Epoch 50/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2719.2146\n",
      "Epoch 51/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2719.8027\n",
      "Epoch 52/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2718.5442\n",
      "Epoch 53/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2727.5181\n",
      "Epoch 54/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2725.8689\n",
      "Epoch 55/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2719.2947\n",
      "Epoch 56/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2721.7737\n",
      "Epoch 57/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2721.2749\n",
      "Epoch 58/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2713.9792\n",
      "Epoch 59/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2717.7451\n",
      "Epoch 60/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2718.9109\n",
      "Epoch 61/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2723.5413\n",
      "Epoch 62/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2715.9119\n",
      "Epoch 63/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2718.8772\n",
      "Epoch 64/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2716.2705\n",
      "Epoch 65/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2712.3103\n",
      "Epoch 66/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2718.4519\n",
      "Epoch 67/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2714.5054\n",
      "Epoch 68/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2714.3325\n",
      "Epoch 69/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2715.9490\n",
      "Epoch 70/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2719.0281\n",
      "Epoch 71/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2716.9819\n",
      "Epoch 72/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2716.7830\n",
      "Epoch 73/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2718.2271\n",
      "Epoch 74/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2715.0105\n",
      "Epoch 75/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2713.7456\n",
      "Epoch 76/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2715.4966\n",
      "Epoch 77/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2714.6106\n",
      "Epoch 78/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2716.7173\n",
      "Epoch 79/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2714.6968\n",
      "Epoch 80/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2711.4761\n",
      "Epoch 81/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2714.0801\n",
      "Epoch 82/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2712.1660\n",
      "Epoch 83/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2715.6611\n",
      "Epoch 84/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2712.4392\n",
      "Epoch 85/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2715.0784\n",
      "Epoch 86/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2714.2502\n",
      "Epoch 87/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2711.9534\n",
      "Epoch 88/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2715.0149\n",
      "Epoch 89/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2713.7129\n",
      "Epoch 90/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2712.2119\n",
      "Epoch 91/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2711.3779\n",
      "Epoch 92/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2715.2502\n",
      "Epoch 93/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2719.8262\n",
      "Epoch 94/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2710.6853\n",
      "Epoch 95/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2713.4607\n",
      "Epoch 96/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2711.8347\n",
      "Epoch 97/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2710.3237\n",
      "Epoch 98/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2717.5334\n",
      "Epoch 99/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2711.3428\n",
      "Epoch 100/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2713.3252\n",
      "Epoch 101/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2708.9263\n",
      "Epoch 102/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2709.2668\n",
      "Epoch 103/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2709.7339\n",
      "Epoch 104/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2711.8091\n",
      "Epoch 105/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2708.2332\n",
      "Epoch 106/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2715.0295\n",
      "Epoch 107/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2712.9692\n",
      "Epoch 108/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2711.8652\n",
      "Epoch 109/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2708.9609\n",
      "Epoch 110/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2709.7910\n",
      "Epoch 111/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2708.3005\n",
      "Epoch 112/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2716.4370\n",
      "Epoch 113/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2706.5256\n",
      "Epoch 114/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2709.4949\n",
      "Epoch 115/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2709.7544\n",
      "Epoch 116/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2709.8843\n",
      "Epoch 117/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2709.5874\n",
      "Epoch 118/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2709.5520\n",
      "Epoch 119/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2708.1809\n",
      "Epoch 120/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2708.9707\n",
      "Epoch 121/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2709.3696\n",
      "Epoch 122/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2708.5107\n",
      "Epoch 123/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2705.4390\n",
      "Epoch 124/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2715.9082\n",
      "Epoch 125/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2708.8120\n",
      "Epoch 126/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2707.9597\n",
      "Epoch 127/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2710.8064\n",
      "Epoch 128/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2708.1382\n",
      "Epoch 129/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2706.7861\n",
      "Epoch 130/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2706.5808\n",
      "Epoch 131/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2706.1021\n",
      "Epoch 132/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2704.8625\n",
      "Epoch 133/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2709.8345\n",
      "Epoch 134/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2709.1279\n",
      "Epoch 135/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2710.4690\n",
      "Epoch 136/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2707.2368\n",
      "Epoch 137/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2708.8223\n",
      "Epoch 138/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2711.1074\n",
      "Epoch 139/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2706.4060\n",
      "Epoch 140/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2707.7461\n",
      "Epoch 141/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2707.8135\n",
      "Epoch 142/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2705.7869\n",
      "Epoch 143/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2704.5144\n",
      "Epoch 144/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2714.4851\n",
      "Epoch 145/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2705.5618\n",
      "Epoch 146/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2709.1433\n",
      "Epoch 147/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2708.5959\n",
      "Epoch 148/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2718.4482\n",
      "Epoch 149/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2708.8440\n",
      "Epoch 150/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2700.6799\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Epoch 1/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2923.1545\n",
      "Epoch 2/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2916.8447\n",
      "Epoch 3/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2921.8638\n",
      "Epoch 4/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2920.1765\n",
      "Epoch 5/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2910.7693\n",
      "Epoch 6/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2917.0320\n",
      "Epoch 7/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2911.7830\n",
      "Epoch 8/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2906.4963\n",
      "Epoch 9/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2910.1892\n",
      "Epoch 10/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2905.7727\n",
      "Epoch 11/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2912.6228\n",
      "Epoch 12/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2907.6367\n",
      "Epoch 13/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2904.8384\n",
      "Epoch 14/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2914.6377\n",
      "Epoch 15/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2905.1731\n",
      "Epoch 16/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2905.9219\n",
      "Epoch 17/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2907.5676\n",
      "Epoch 18/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2903.2007\n",
      "Epoch 19/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2904.6704\n",
      "Epoch 20/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2906.1521\n",
      "Epoch 21/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2902.4456\n",
      "Epoch 22/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2907.1238\n",
      "Epoch 23/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2897.3999\n",
      "Epoch 24/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2897.8186\n",
      "Epoch 25/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2899.5752\n",
      "Epoch 26/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2895.4478\n",
      "Epoch 27/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2908.6248\n",
      "Epoch 28/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2898.9404\n",
      "Epoch 29/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2900.1296\n",
      "Epoch 30/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2907.1592\n",
      "Epoch 31/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2898.3882\n",
      "Epoch 32/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2896.7605\n",
      "Epoch 33/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2900.7893\n",
      "Epoch 34/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2893.8540\n",
      "Epoch 35/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2898.8582\n",
      "Epoch 36/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2898.3567\n",
      "Epoch 37/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2898.7307\n",
      "Epoch 38/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2897.9277\n",
      "Epoch 39/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2892.9910\n",
      "Epoch 40/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2902.3760\n",
      "Epoch 41/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2901.4343\n",
      "Epoch 42/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2893.8733\n",
      "Epoch 43/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2895.9143\n",
      "Epoch 44/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2891.5308\n",
      "Epoch 45/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2901.7410\n",
      "Epoch 46/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2895.0374\n",
      "Epoch 47/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2895.3516\n",
      "Epoch 48/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2894.6125\n",
      "Epoch 49/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2893.5750\n",
      "Epoch 50/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2899.7588\n",
      "Epoch 51/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2893.6685\n",
      "Epoch 52/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2890.6863\n",
      "Epoch 53/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2894.5369\n",
      "Epoch 54/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2892.2515\n",
      "Epoch 55/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2891.7258\n",
      "Epoch 56/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2890.4900\n",
      "Epoch 57/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2889.3757\n",
      "Epoch 58/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2890.4333\n",
      "Epoch 59/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2889.7952\n",
      "Epoch 60/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2893.9065\n",
      "Epoch 61/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2897.0613\n",
      "Epoch 62/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2887.2996\n",
      "Epoch 63/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2895.1130\n",
      "Epoch 64/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2893.6741\n",
      "Epoch 65/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2896.7783\n",
      "Epoch 66/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2894.7134\n",
      "Epoch 67/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2888.9988\n",
      "Epoch 68/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2890.0532\n",
      "Epoch 69/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2895.8057\n",
      "Epoch 70/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2893.2119\n",
      "Epoch 71/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2890.3813\n",
      "Epoch 72/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2898.5430\n",
      "Epoch 73/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2892.1216\n",
      "Epoch 74/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2892.3936\n",
      "Epoch 75/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2889.4226\n",
      "Epoch 76/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2891.8123\n",
      "Epoch 77/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2889.2561\n",
      "Epoch 78/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2891.9333\n",
      "Epoch 79/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2892.4456\n",
      "Epoch 80/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2894.6899\n",
      "Epoch 81/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2886.2561\n",
      "Epoch 82/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2893.9507\n",
      "Epoch 83/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2887.7134\n",
      "Epoch 84/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2890.8638\n",
      "Epoch 85/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2885.8076\n",
      "Epoch 86/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2907.7632\n",
      "Epoch 87/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2886.1509\n",
      "Epoch 88/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2890.5979\n",
      "Epoch 89/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2896.8779\n",
      "Epoch 90/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2892.7778\n",
      "Epoch 91/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2896.3413\n",
      "Epoch 92/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2889.6426\n",
      "Epoch 93/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2891.1096\n",
      "Epoch 94/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2896.4744\n",
      "Epoch 95/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2890.9863\n",
      "Epoch 96/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2891.1992\n",
      "Epoch 97/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2893.4521\n",
      "Epoch 98/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2886.6904\n",
      "Epoch 99/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2886.4333\n",
      "Epoch 100/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2887.4141\n",
      "Epoch 101/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2884.1458\n",
      "Epoch 102/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2888.9211\n",
      "Epoch 103/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2884.5227\n",
      "Epoch 104/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2896.0066\n",
      "Epoch 105/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2886.8423\n",
      "Epoch 106/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2888.3306\n",
      "Epoch 107/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2890.7063\n",
      "Epoch 108/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2884.5117\n",
      "Epoch 109/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2895.9092\n",
      "Epoch 110/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2885.3989\n",
      "Epoch 111/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2890.1711\n",
      "Epoch 112/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2882.4414\n",
      "Epoch 113/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2886.0520\n",
      "Epoch 114/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2884.8613\n",
      "Epoch 115/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2885.5222\n",
      "Epoch 116/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2888.1042\n",
      "Epoch 117/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2898.3159\n",
      "Epoch 118/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2882.6667\n",
      "Epoch 119/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2886.2896\n",
      "Epoch 120/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2890.2351\n",
      "Epoch 121/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2884.4397\n",
      "Epoch 122/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2886.6660\n",
      "Epoch 123/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2885.0120\n",
      "Epoch 124/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2898.1504\n",
      "Epoch 125/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2886.2266\n",
      "Epoch 126/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2899.9373\n",
      "Epoch 127/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2887.9761\n",
      "Epoch 128/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2885.0715\n",
      "Epoch 129/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2882.8159\n",
      "Epoch 130/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2897.0159\n",
      "Epoch 131/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2883.7192\n",
      "Epoch 132/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2884.2676\n",
      "Epoch 133/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2890.6130\n",
      "Epoch 134/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2883.7344\n",
      "Epoch 135/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2888.8943\n",
      "Epoch 136/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2886.6631\n",
      "Epoch 137/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2886.7258\n",
      "Epoch 138/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2886.7383\n",
      "Epoch 139/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2889.1282\n",
      "Epoch 140/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2884.9971\n",
      "Epoch 141/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2883.8601\n",
      "Epoch 142/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2884.6387\n",
      "Epoch 143/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2889.9565\n",
      "Epoch 144/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2891.0234\n",
      "Epoch 145/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2897.7383\n",
      "Epoch 146/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2889.2012\n",
      "Epoch 147/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2891.0322\n",
      "Epoch 148/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2883.1763\n",
      "Epoch 149/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2880.7480\n",
      "Epoch 150/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 2883.5674\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "Mean Squared Error: 2967.916536951096\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Import the diabetes dataset\n",
    "data = datasets.load_diabetes()\n",
    "x = data.data\n",
    "y = data.target\n",
    "\n",
    "n_features = x.shape[1]\n",
    "\n",
    "# Define MLP model\n",
    "clf = Sequential()\n",
    "clf.add(Dense(10, input_dim=n_features, activation='relu'))\n",
    "clf.add(Dense(10, activation='relu'))\n",
    "clf.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile model\n",
    "clf.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "mse_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(x,y):\n",
    "    x_train = x[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    x_test = x[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    # Training phase\n",
    "    clf.fit(x_train, y_train, epochs=150, batch_size=5)\n",
    "\n",
    "    # Test phase\n",
    "    y_pred = clf.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "\n",
    "MSE = np.mean(mse_scores)\n",
    "print(f'Mean Squared Error: {MSE}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
